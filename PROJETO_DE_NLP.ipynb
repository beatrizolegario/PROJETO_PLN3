{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatrizolegario/PROJETO_PLN3/blob/main/PROJETO_DE_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Processamento de Linguagem Natural [2024-Q2]**\n",
        "Prof. Alexandre Donizeti Alves"
      ],
      "metadata": {
        "id": "UOckxIAeGyr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01: Thiago Bibiano Silva**\n",
        "\n",
        "`RA: 11201920950`\n",
        "\n",
        "**Integrante 02: Bruno José Machado de Camargo**\n",
        "\n",
        "`RA: 11019814`\n",
        "\n",
        "**Integrante 03: Beatriz Santos Olegario**\n",
        "\n",
        "`RA: 11202022106`\n"
      ],
      "metadata": {
        "id": "e2Rd07zXG12F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução\n",
        "\n",
        "Nos últimos anos, o Processamento de Linguagem Natural (PLN) tem se tornado uma área de crescente interesse, especialmente em aplicações que envolvem a extração de informações de documentos técnicos e a geração de respostas a partir de grandes volumes de dados textuais. Normas e regulamentos, como a NBR 9050 sobre acessibilidade, são exemplos de documentos que demandam interpretação cuidadosa e muitas vezes são de difícil acesso para o público geral. Nesse contexto, este trabalho visa desenvolver um sistema de **RAG (Retrieval-Augmented Generation)** para facilitar a consulta a esses documentos por meio de um sistema de **perguntas e respostas**.\n",
        "\n",
        "O projeto propõe a criação de um **Knowledge Graph** (KG) baseado na extração de informações estruturadas, como triplas, a partir de textos técnicos. A construção do KG segue os princípios descritos no artigo de referência \"Knowledge Graph-Augmented Language Models for Information Retrieval\" (Gao et al., 2023) , que explora métodos avançados de integração de gráficos de conhecimento com modelos de linguagem, para aprimorar a precisão e relevância das respostas geradas em um sistema de perguntas e respostas. Este sistema permitirá aos usuários acessar rapidamente informações sobre normas técnicas e regulamentos, respondendo a consultas com base em um gráfico de conhecimento extraído de fontes como a NBR 9050.\n",
        "\n",
        "Além da extração de texto a partir de PDFs, o sistema contará com mecanismos de processamento e organização de dados textuais, garantindo que o conteúdo seja dividido por tópicos, removendo informações redundantes como cabeçalhos e rodapés, e permitindo que as respostas sejam geradas com base nas informações estruturadas contidas no KG. A implementação do sistema será feita utilizando a linguagem de programação Python e o framework LangChain, com suporte de ferramentas como Google Colab para o desenvolvimento e testes."
      ],
      "metadata": {
        "id": "nbZBkh44MnFs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6gi7ZcIxzp6",
        "outputId": "0cf36dbf-4589-437c-cc7f-b8e0a7482b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: maritalk in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.38)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.4)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.116)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from maritalk) (0.27.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from maritalk) (4.44.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->maritalk) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->maritalk) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->maritalk) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->maritalk) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->maritalk) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->maritalk) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->maritalk) (0.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers->maritalk) (2024.6.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->maritalk) (1.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain networkx pandas PyPDF2 spacy tiktoken maritalk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configurações Iniciais"
      ],
      "metadata": {
        "id": "WwMBaD_HSYi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Importações"
      ],
      "metadata": {
        "id": "tKG6tqdHw7SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import maritalk\n",
        "from PyPDF2 import PdfReader\n",
        "import requests\n",
        "import re\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import userdata\n",
        "import plotly.graph_objects as go\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "JkYjO6FEmVBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o caminho base\n",
        "base_path = '/content/projeto_de_nlp'\n",
        "\n",
        "# Estrutura de diretórios\n",
        "dirs = [\n",
        "    os.path.join(base_path, 'data')\n",
        "    ]\n",
        "\n",
        "# Criar diretórios\n",
        "for dir in dirs:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "# Confirmar a criação da estrutura\n",
        "print(\"Estrutura de diretórios criada:\")\n",
        "for dir in dirs:\n",
        "    print(dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79edNjH11-8_",
        "outputId": "3d3dca8a-6fe1-457d-ae51-933f5b583b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura de diretórios criada:\n",
            "/content/projeto_de_nlp/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descrição**:\n",
        "1. O código define o caminho base para a estrutura de diretórios do projeto.\n",
        "2. Cria uma lista com os diretórios que serão criados.\n",
        "3. Usa `os.makedirs` para criar os diretórios, garantindo que não haverá erro se eles já existirem (`exist_ok=True`).\n",
        "4. Por fim, imprime a confirmação da criação dos diretórios no console."
      ],
      "metadata": {
        "id": "ZEz9MApwwwQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "def configure_maritaca():\n",
        "    \"\"\"\n",
        "    Configura a API da Maritaca utilizando uma chave de API armazenada como um secret no Google Colab.\n",
        "    \"\"\"\n",
        "    # Pegue a chave de API da Maritaca dos Secrets do Google Colab\n",
        "    maritaca_api_key = userdata.get(\"MARITALK_API_KEY\")\n",
        "\n",
        "    if not maritaca_api_key:\n",
        "        raise ValueError(\"A chave da API da Maritaca não foi encontrada. Defina o secret 'MARITALK_API_KEY' no Google Colab.\")\n",
        "\n",
        "    return maritaca_api_key\n",
        "\n",
        "# Configurar a API da Maritaca e obter a chave\n",
        "api_key = configure_maritaca()\n"
      ],
      "metadata": {
        "id": "14GI2HqJmJ9v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "29a49b33-e5dd-4402-d408-e80e1659d25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret MARITALK_API_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-651403515f86>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Configurar a API da Maritaca e obter a chave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigure_maritaca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-651403515f86>\u001b[0m in \u001b[0;36mconfigure_maritaca\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Pegue a chave de API da Maritaca dos Secrets do Google Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmaritaca_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MARITALK_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaritaca_api_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret MARITALK_API_KEY does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descrição**:\n",
        "1. A função `configure_maritaca()` busca a chave de API da Maritaca armazenada como um secret no Google Colab (`MARITALK_API_KEY`).\n",
        "2. Se a chave não for encontrada, a função lança um erro informando ao usuário que a chave não está definida.\n",
        "3. Retorna a chave da API para ser utilizada em outras partes da aplicação.\n",
        "4. A variável `api_key` recebe a chave de API após a chamada da função."
      ],
      "metadata": {
        "id": "Y06WvDYyxCNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Download do PDF\n"
      ],
      "metadata": {
        "id": "H4AQ1MmUTBbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para realizar o download do PDF\n",
        "def download_pdf(url, output_path):\n",
        "    \"\"\"\n",
        "    Faz o download de um PDF a partir de uma URL e salva no caminho especificado.\n",
        "\n",
        "    Parâmetros:\n",
        "    url (str): O link direto para o arquivo PDF que será baixado.\n",
        "    output_path (str): O caminho onde o PDF será salvo localmente.\n",
        "\n",
        "    Retorno:\n",
        "    None: O PDF é salvo no caminho especificado e uma mensagem de sucesso é exibida.\n",
        "    \"\"\"\n",
        "    # Realizar a requisição HTTP para baixar o conteúdo do PDF\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Verificar se a requisição foi bem-sucedida (código de status 200)\n",
        "    if response.status_code == 200:\n",
        "        # Abrir o arquivo no modo de escrita binária (wb) e salvar o conteúdo\n",
        "        with open(output_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        # Exibir mensagem de sucesso\n",
        "        print(f\"PDF salvo em: {output_path}\")\n",
        "    else:\n",
        "        # Se a requisição falhar, exibir mensagem de erro\n",
        "        print(f\"Erro ao baixar o PDF. Código de status: {response.status_code}\")\n",
        "\n",
        "# Definir a URL do PDF que será baixado\n",
        "url = 'https://www.prefeitura.sp.gov.br/cidade/secretarias/upload/NBR9050_20.pdf'\n",
        "\n",
        "# Definir o caminho de saída onde o PDF será salvo no Google Colab\n",
        "# O diretório '/content' é o padrão no Google Colab, e estamos salvando o PDF dentro de um diretório 'data' dentro da pasta do projeto 'projeto_de_nlp'\n",
        "output_path = '/content/projeto_de_nlp/data/NBR9050_20.pdf'\n",
        "\n",
        "# Chamar a função para fazer o download do PDF\n",
        "download_pdf(url, output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6RIfyO2Sfo-",
        "outputId": "efc05d5e-9aac-496c-f651-d41649e5f762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF salvo em: /content/projeto_de_nlp/data/NBR9050_20.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descrição**:\n",
        "1. A função `download_pdf()` realiza o download de um arquivo PDF a partir de uma URL e salva-o no local especificado.\n",
        "2. O parâmetro `url` representa o link direto para o PDF, e `output_path` especifica onde o PDF será armazenado localmente.\n",
        "3. A função usa uma requisição HTTP para baixar o conteúdo e salva o PDF em modo binário no caminho fornecido.\n",
        "4. Caso o download seja bem-sucedido (código de status 200), uma mensagem é exibida confirmando o local onde o PDF foi salvo. Se ocorrer um erro, o código de status da requisição será exibido.\n",
        "5. A URL e o caminho de saída são definidos para o download do PDF da NBR 9050, que será utilizado para aplicar técnicas de Knowledge Graph Retrieval-Augmented Generation (KG-RAG)."
      ],
      "metadata": {
        "id": "tfH0Y9_bxVGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Processamento do PDF (Extração de Texto)"
      ],
      "metadata": {
        "id": "efWbCGfGS-Yx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sessão mencionada tem dois objetivos principais:\n",
        "\n",
        "1. **Extrair e limpar o texto de um PDF**: O código lê o PDF (NBR9050), remove cabeçalhos e rodapés, e limpa o texto eliminando quebras de linha e espaços desnecessários. O texto processado é salvo em um arquivo de texto (`cleaned_pdf_text.txt`).\n",
        "\n",
        "2. **Estimar a quantidade de tokens**: O segundo código lê o texto limpo, usa a codificação do GPT-4 para dividir o conteúdo em tokens e estima quantos tokens são necessários para processar o texto. Isso é útil ao trabalhar com limites de tokens em modelos de linguagem como GPT-4.\n",
        "\n",
        "Esses dois passos são importantes para preparar e medir o conteúdo antes de aplicá-lo em tarefas de processamento de linguagem natural, como a criação de um KG-RAG."
      ],
      "metadata": {
        "id": "TPqMFT6vyQ0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Limpa o texto extraído para remover quebras de linha desnecessárias e formatar o conteúdo.\n",
        "\n",
        "    Parâmetros:\n",
        "    text (str): O texto bruto extraído do PDF.\n",
        "\n",
        "    Retorno:\n",
        "    str: O texto limpo e formatado.\n",
        "    \"\"\"\n",
        "    clean_lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
        "    cleaned_text = \" \".join(clean_lines)\n",
        "    return cleaned_text\n",
        "\n",
        "def extract_topic_line(line):\n",
        "    \"\"\"\n",
        "    Extrai títulos e números de páginas de linhas no formato: título .......... página.\n",
        "\n",
        "    Parâmetros:\n",
        "    line (str): Linha de texto extraída.\n",
        "\n",
        "    Retorno:\n",
        "    tuple: O título e o número da página (se encontrados), caso contrário (None, None).\n",
        "    \"\"\"\n",
        "    match = re.search(r\"(.+?)\\s+\\.{2,}\\s+(\\d+)\", line)\n",
        "    if match:\n",
        "        title = match.group(1).strip()\n",
        "        page_num = match.group(2).strip()\n",
        "        return title, page_num\n",
        "    return None, None\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extrai o texto de todas as páginas de um arquivo PDF, lidando de forma especial com as páginas de sumário (3 a 12),\n",
        "    e removendo cabeçalhos e rodapés das páginas restantes.\n",
        "\n",
        "    Parâmetros:\n",
        "    pdf_path (str): O caminho para o arquivo PDF que será processado.\n",
        "\n",
        "    Retorno:\n",
        "    str: O texto extraído e limpo de todas as páginas concatenado.\n",
        "    \"\"\"\n",
        "    reader = PdfReader(pdf_path)\n",
        "    all_text = []\n",
        "    full_summary_data = \"\"\n",
        "\n",
        "    # Definir os limites Y para ignorar cabeçalhos e rodapés\n",
        "    y_min = 70   # Ajuste conforme necessário\n",
        "    y_max = 770  # Ajuste conforme necessário\n",
        "\n",
        "    def visitor_body(text, cm, tm, fontDict, fontSize):\n",
        "        y = tm[5]  # Posição Y do texto na página\n",
        "        if y_min < y < y_max:\n",
        "            all_text.append(text)\n",
        "\n",
        "    # Processar as páginas do sumário (3 a 12) de forma especial\n",
        "    for page_num in range(2, 12):\n",
        "        page = reader.pages[page_num]\n",
        "        page_text = page.extract_text()\n",
        "\n",
        "        # Limpar o texto extraído\n",
        "        cleaned_page_text = clean_text(page_text)\n",
        "        full_summary_data += cleaned_page_text\n",
        "\n",
        "    summary_data = clean_text(full_summary_data)\n",
        "\n",
        "\n",
        "    # Processar as páginas restantes (após a página 12), removendo cabeçalhos e rodapés\n",
        "    for page_num in range(14, len(reader.pages)):\n",
        "        page = reader.pages[page_num]\n",
        "        page.extract_text(visitor_text=visitor_body)\n",
        "\n",
        "    # Concatenar todo o texto extraído e limpar\n",
        "    full_text = \"\".join(all_text)\n",
        "    cleaned_text = clean_text(full_text)\n",
        "\n",
        "    return cleaned_text, summary_data\n",
        "\n",
        "# Definir o caminho do PDF que será processado\n",
        "pdf_path = '/content/projeto_de_nlp/data/NBR9050_20.pdf'\n",
        "\n",
        "# Chamar a função para extrair o texto do PDF\n",
        "pdf_text, index = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Salvar o texto limpo em um arquivo de fácil leitura\n",
        "output_text_path = '/content/projeto_de_nlp/data/cleaned_pdf_text.txt'\n",
        "\n",
        "with open(output_text_path, 'w') as f:\n",
        "    f.write(pdf_text)\n",
        "\n",
        "print(f\"Texto extraído e salvo em {output_text_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA4b3c8ISfmD",
        "outputId": "71008332-3d8e-46ce-9529-182064fc746b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto extraído e salvo em /content/projeto_de_nlp/data/cleaned_pdf_text.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descrição**:\n",
        "1. **`clean_text()`**: Limpa o texto removendo quebras de linha e espaços desnecessários, unindo as linhas em um único bloco.\n",
        "2. **`extract_topic_line()`**: Extrai títulos e números de página de linhas que seguem o formato \"título .......... página\".\n",
        "3. **`extract_text_from_pdf()`**: Extrai o texto de um PDF, processando o sumário (páginas 3 a 12) separadamente, e removendo cabeçalhos e rodapés das páginas restantes.\n",
        "4. O código salva o texto extraído em um arquivo `.txt` para facilitar a leitura e processamento subsequente, sendo útil em um processo de criação de um KG-RAG (Knowledge Graph Retrieval-Augmented Generation)."
      ],
      "metadata": {
        "id": "woNh4qrvx3Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usando a codificação do modelo gpt-4 para estimar a quantidade de tokens\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "\n",
        "with open(output_text_path, 'r') as f:\n",
        "    # Conta os tokens\n",
        "    tokens = encoding.encode(f.readlines()[0])\n",
        "    print(f\"O número de tokens estimados é: {len(tokens)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4U8INhZuoxQ",
        "outputId": "6efadf2c-cb85-4f59-dfb0-7140103175bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número de tokens estimados é: 65912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descrição**:\n",
        "1. **Codificação**: A função `tiktoken.encoding_for_model(\"gpt-4\")` obtém a codificação específica do modelo GPT-4, que é utilizada para contar tokens.\n",
        "2. **Leitura do arquivo**: O arquivo de texto limpo, salvo previamente no caminho `output_text_path`, é aberto.\n",
        "3. **Contagem de tokens**: O código lê a primeira linha do arquivo e a codifica em tokens usando a codificação do GPT-4.\n",
        "4. **Impressão do resultado**: O número total de tokens da primeira linha do arquivo é calculado e impresso no console."
      ],
      "metadata": {
        "id": "wbA3AjtKyZpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Extração de Triplas com a API da Maritaca"
      ],
      "metadata": {
        "id": "sd46LvHbS63Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seção 4 do artigo baseia-se na **extração de triplas** a partir de dados não estruturados para transformá-los em um **grafo de conhecimento** (KG). O processo de extração de triplas é fundamental na construção do KG para realizar **Knowledge Graph Retrieval-Augmented Generation (KG-RAG)**, permitindo uma recuperação mais precisa de informações e respostas mais contextualmente ricas.\n",
        "\n",
        "## 4.1 Código para Extração de Triplas:\n",
        "1. **Detecção de Tópicos**: A função `detect_topics()` identifica padrões numéricos de tópicos e subtópicos, como \"5.1\" ou \"5.2.3\", dentro do texto. O objetivo é mapear a estrutura dos tópicos e organizar o conteúdo com base nesses índices.\n",
        "   \n",
        "2. **Divisão do Texto por Tópicos**: A função `divide_text_by_topics()` divide o texto em \"chunks\", baseando-se na detecção de tópicos. Cada chunk corresponde ao texto entre dois tópicos, facilitando a organização e a extração posterior de triplas."
      ],
      "metadata": {
        "id": "LMvlrO4AzOmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para detectar tópicos e subtópicos\n",
        "# Atualizando a função para capturar apenas tópicos de padrões válidos\n",
        "def detect_topics(text):\n",
        "    \"\"\"\n",
        "    Detecta tópicos e subtópicos em um texto sem quebras de linha.\n",
        "    Retorna apenas o índice numérico do tópico (ex: '5.1', '5.2.3').\n",
        "    \"\"\"\n",
        "    # Padrão regex para capturar tópicos com pelo menos um ponto (ex: \"5\", \"5.1\", \"5.1.2\")\n",
        "    topic_pattern = r'(?<!\\d)(\\d+(\\.\\d+)*)(?![\\w\\d])'\n",
        "\n",
        "    # Detectar todos os tópicos válidos no texto\n",
        "    matches = re.finditer(topic_pattern, text)\n",
        "\n",
        "    topics = []\n",
        "    for match in matches:\n",
        "        # Adicionar o índice numérico do tópico detectado\n",
        "        # Filtrar para ignorar números soltos (sem pontos)\n",
        "        if \".\" in match.group(1):\n",
        "            topics.append(match.group(1).split('.')[0])\n",
        "            topics.append(match.group(1))\n",
        "\n",
        "    if not topics:  # Verifica se algum tópico foi detectado\n",
        "        return \"Tópicos não detectados\"\n",
        "\n",
        "    topics = list(dict.fromkeys(topics))\n",
        "    topics.insert(0, \"2\")\n",
        "    topics.insert(0, \"1\")\n",
        "    return topics\n",
        "\n",
        "def divide_text_by_topics(text, index):\n",
        "    \"\"\"\n",
        "    Divide o texto de acordo com os tópicos detectados. Um chunk é criado a partir do tópico atual\n",
        "    e é encerrado apenas quando o próximo tópico é encontrado.\n",
        "    \"\"\"\n",
        "\n",
        "    topics = detect_topics(index)  # Detectar tópicos e subtópicos no texto\n",
        "\n",
        "    chunks = []  # Lista para armazenar os chunks gerados\n",
        "    current_chunk = []  # Chunk atual sendo construído\n",
        "    current_topic = None  # Tópico atual\n",
        "    total_tokens = text.split()  # Dividindo o texto em tokens (palavras)\n",
        "\n",
        "    initial = 0\n",
        "    final = len(total_tokens)\n",
        "\n",
        "    while topics:\n",
        "        current_topic = topics.pop(0)  # Pega o primeiro tópico e remove da lista\n",
        "        for word_index, word in enumerate(total_tokens[initial:], start=initial):\n",
        "            # Verificar se a palavra atual corresponde ao tópico\n",
        "            if re.sub(r'[^\\W\\d_]', '', word) == current_topic:\n",
        "                # Se já houver um chunk sendo construído, salvá-lo\n",
        "                if initial != word_index:\n",
        "                    current_chunk = total_tokens[initial: word_index]  # Cria o chunk até o índice atual\n",
        "                    chunks.append(\n",
        "                        \" \".join(current_chunk)  # Adicionar o chunk gerado\n",
        "                    )\n",
        "\n",
        "                # Atualizar o início para o índice atual\n",
        "                initial = word_index\n",
        "                break  # Interrompe o loop de palavras para verificar o próximo tópico\n",
        "\n",
        "    # Adicionar o último chunk, se houver\n",
        "    if initial < final:\n",
        "        chunks.append(\n",
        "            \" \".join(total_tokens[initial: final])  # Pega o restante do texto\n",
        "        )\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "lH4yGQFqSfec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o texto limpo do PDF\n",
        "with open('/content/projeto_de_nlp/data/cleaned_pdf_text.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Dividir o texto por tópicos e subtópicos, mantendo o limite de tokens\n",
        "chunks = divide_text_by_topics(text, index)"
      ],
      "metadata": {
        "id": "z3b1tIyh2DIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Criação de Triplas Contextuais\n",
        "\n",
        "Este código usa o modelo **Sabia-3 da Maritaca** para extrair triplas (Sujeito, Relacionamento, Objeto) a partir de *chunks* de texto técnico, como o da norma **NBR9050**. O processo de extração é feito através de um **modelo de linguagem natural (LLM)**, e as triplas extraídas são úteis para estruturar informações em grafos de conhecimento (KG), que serão usados em **Knowledge Graph Retrieval-Augmented Generation (KG-RAG)**.\n",
        "\n",
        "**Passos do código:**\n",
        "1. **Configuração da API da Maritaca**: A chave da API é obtida e configurada para autenticação no modelo `MariTalk`.\n",
        "2. **Prompt de extração de triplas**: Cada *chunk* de texto é passado para o modelo LLM com um *prompt* detalhado que pede a extração de triplas no formato (Sujeito, Relacionamento, Objeto). O *prompt* é ajustado para o contexto da NBR9050, pedindo triplas relacionadas a padrões técnicos e diretrizes.\n",
        "3. **Resposta do modelo**: O modelo Sabia-3 gera as triplas com base no texto fornecido. Se o texto não for relevante, o modelo retorna uma tupla vazia `(,,)` para evitar resultados irrelevantes.\n",
        "4. **Coleta de triplas**: As triplas extraídas de cada *chunk* são armazenadas em uma lista para posterior uso.\n",
        "\n",
        "Este código é essencial para construir **grafos de conhecimento** a partir de documentos normativos como a NBR9050, estruturando as informações de forma útil para consultas automatizadas e respostas contextuais."
      ],
      "metadata": {
        "id": "nDE5TX5x0E4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import maritalk\n",
        "\n",
        "def extract_triples_using_llm(chunks, model='sabia-2-small'):\n",
        "    \"\"\"\n",
        "    Utiliza o modelo LLM Sabia-3 da Maritaca para extrair triplas (Sujeito, Relacionamento, Objeto) de cada chunk de texto.\n",
        "    Não há mais associação direta com tópicos, apenas o texto é considerado.\n",
        "\n",
        "    Parâmetros:\n",
        "    - chunks (list): Lista de chunks de texto (apenas strings).\n",
        "    - model (str): Modelo LLM da OpenAI a ser utilizado para a extração de triplas. Padrão é 'sabia-2-small'.\n",
        "\n",
        "    Retorna:\n",
        "    - list: Lista de triplas extraídas, sem associação a tópicos.\n",
        "    \"\"\"\n",
        "\n",
        "    # Configurar o modelo MariTalk da Maritaca\n",
        "    api_key = configure_maritaca()\n",
        "    model_instance = maritalk.MariTalk(key=api_key, model=model)\n",
        "\n",
        "    # Template para extrair triplas\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"chunk\"],\n",
        "        template=\"\"\"\n",
        "        # Contexto:\n",
        "        Extraia todas as triplas no formato (\"Sujeito\", \"Relacionamento\", \"Objeto\") do seguinte texto técnico da norma NBR9050 sobre acessibilidade. Concentre-se em identificar entidades relacionadas a padrões, requisitos técnicos, recomendações e diretrizes normativas. Se as dimensões estiverem no texto, extraia-as nas triplas também.\n",
        "\n",
        "        Se a entrada não tiver pertinência à solicitação, retorne uma lista com uma tupla com 3 espaços vazios. A saída deve ser uma lista de tuplas, como nos exemplos abaixo.\n",
        "\n",
        "        # Exemplo:\n",
        "\n",
        "        ## Texto1:\n",
        "        4.3.6 Posicionamento de cadeiras de rodas em espaços confinados. A Figura 9 exemplifica condições para posicionamento de cadeiras de rodas em nichos ou espaços confinados. Dimensões em metros: a) Espaço confinado perpendicular (1,20 m x 0,80 m); b) Espaço confinado paralelo (1,30 m x 0,90 m).\n",
        "\n",
        "        ## Saída1:\n",
        "        [(\"Posicionamento de cadeiras de rodas\", \"ocorre em\", \"espaços confinados\"),\n",
        "        (\"Figura 9\", \"exemplifica\", \"condições para posicionamento de cadeiras de rodas\"),\n",
        "        (\"Espaço confinado perpendicular\", \"tem dimensões de\", \"1,20 m x 0,80 m\"),\n",
        "        (\"Espaço confinado paralelo\", \"tem dimensões de\", \"1,30 m x 0,90 m\")]\n",
        "\n",
        "        ## Texto2:\n",
        "        Que bela manhã de sol no ABC.\n",
        "\n",
        "        ## Saída2:\n",
        "        [(,,)]\n",
        "\n",
        "        # Agora, aplique o mesmo processo ao seguinte texto e, em seguida, extraia apenas as triplas no formato solicitado:\n",
        "        {chunk}\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    all_triples = []\n",
        "\n",
        "    # Processar cada chunk de texto\n",
        "    for chunk in chunks:\n",
        "        # Formatar o prompt\n",
        "        formatted_prompt = prompt_template.format(chunk=chunk)\n",
        "\n",
        "        # Criar a cadeia LLM com o LangChain\n",
        "        llm_chain = LLMChain(\n",
        "            llm=model_instance,\n",
        "            prompt=formatted_prompt\n",
        "        )\n",
        "\n",
        "        # Geração da resposta usando o LangChain\n",
        "        response = llm_chain.run()\n",
        "\n",
        "        # Adicionar as triplas extraídas à lista\n",
        "        all_triples.append(response.strip())\n",
        "\n",
        "    return all_triples"
      ],
      "metadata": {
        "id": "tNbDC7RUbTEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair triplas utilizando o LLM da OpenAI\n",
        "triples = extract_triples_using_llm(chunks, 'sabia-3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXCs7p9v2F-L",
        "outputId": "daa2bb4f-129d-4d08-9316-0e137ff44e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API da Maritaca configurada com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Armazenamento de Triplas\n",
        "\n",
        "O código fornecido transforma textos contendo triplas no formato `(Sujeito, Relacionamento, Objeto)` em um arquivo CSV com as colunas **subject**, **relation**, e **object**.\n",
        "\n",
        "**Funcionamento:**\n",
        "1. **Importações**: São importados `pandas` para manipulação de dados e `ast` para avaliar strings que contêm listas de triplas.\n",
        "   \n",
        "2. **Extração de triplas**:\n",
        "   - O código usa a função `extract_between_brackets()` para extrair o conteúdo entre colchetes `[]` dentro de cada texto, que é onde as triplas são esperadas.\n",
        "   - Se o texto contém triplas, ele usa `ast.literal_eval()` para converter a string da lista de triplas em uma estrutura de lista Python.\n",
        "   - As triplas são adicionadas a uma lista, removendo espaços em branco ao redor de cada elemento (sujeito, relação, objeto).\n",
        "   \n",
        "3. **Armazenamento em CSV**:\n",
        "   - Após processar todas as triplas, os dados são convertidos em um **DataFrame** do pandas.\n",
        "   - O DataFrame é então salvo em um arquivo CSV, que pode ser usado para análises posteriores."
      ],
      "metadata": {
        "id": "0QtMBmyF0g-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast  # Para avaliar a string de listas como listas reais\n",
        "\n",
        "def texts_to_triples_csv(texts, output_file='triples.csv'):\n",
        "    \"\"\"\n",
        "    Função para transformar um conjunto de textos contendo triplas (Sujeito, Relação, Objeto)\n",
        "    em um arquivo CSV com as colunas 'subject', 'relation', 'object', extraindo somente o conteúdo entre colchetes [].\n",
        "\n",
        "    Parâmetros:\n",
        "    texts (list): Lista de strings contendo triplas no formato (sujeito, relação, objeto).\n",
        "    output_file (str): Nome do arquivo CSV de saída (default: 'triples.csv').\n",
        "\n",
        "    Retorna:\n",
        "    None. O arquivo CSV é gerado no caminho especificado.\n",
        "    \"\"\"\n",
        "    # Inicializar uma lista para armazenar os dados\n",
        "    data = []\n",
        "\n",
        "    # Função auxiliar para extrair o conteúdo entre colchetes []\n",
        "    def extract_between_brackets(text):\n",
        "        # Extrair o conteúdo entre o primeiro '[' e o último ']'\n",
        "        match = re.search(r'\\[.*\\]', text, flags=re.DOTALL)\n",
        "        if match:\n",
        "            return match.group(0)  # Retorna o conteúdo encontrado entre os colchetes\n",
        "        return None\n",
        "\n",
        "    # Processar cada texto\n",
        "    for text in texts:\n",
        "        # Extrair o conteúdo entre colchetes\n",
        "        extracted_text = extract_between_brackets(text)\n",
        "\n",
        "        if extracted_text:\n",
        "            try:\n",
        "                # Avaliar o texto para converter de string para lista de triplas\n",
        "                triples = ast.literal_eval(extracted_text)\n",
        "\n",
        "                # Adicionar as triplas à lista de dados\n",
        "                for triple in triples:\n",
        "                    if len(triple) == 3:\n",
        "                        data.append({\n",
        "                            'subject': triple[0].strip(),\n",
        "                            'relation': triple[1].strip(),\n",
        "                            'object': triple[2].strip()\n",
        "                        })\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar o texto: {text[:30]}... Erro: {e}\")\n",
        "        else:\n",
        "            print(f\"Texto ignorado: {text[:30]}\")\n",
        "\n",
        "    # Converter os dados em um DataFrame do pandas\n",
        "    if data:\n",
        "        df = pd.DataFrame(data, columns=['subject', 'relation', 'object'])\n",
        "\n",
        "        # Salvar o DataFrame em um arquivo CSV\n",
        "        df.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"Triplas salvas no arquivo: {output_file}\")\n",
        "    else:\n",
        "        print(\"Nenhuma tripla válida foi encontrada.\")\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "kDQUTBNvIvMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_triples = texts_to_triples_csv(triples, 'projeto_de_nlp/data/triples.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HULOWNwMWKXn",
        "outputId": "7e6eb439-d8d5-41d6-a3b9-5779679dce01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro ao processar o texto: [(,,)]... Erro: invalid syntax (<unknown>, line 1)\n",
            "Erro ao processar o texto: [(,,)]... Erro: invalid syntax (<unknown>, line 1)\n",
            "Erro ao processar o texto: [(,,)]... Erro: invalid syntax (<unknown>, line 1)\n",
            "Texto ignorado: Peço desculpas, mas parece que\n",
            "Erro ao processar o texto: [(,,)]... Erro: invalid syntax (<unknown>, line 1)\n",
            "Erro ao processar o texto: [(,,)]... Erro: invalid syntax (<unknown>, line 1)\n",
            "Erro ao processar o texto: [(,,)]... Erro: invalid syntax (<unknown>, line 1)\n",
            "Erro ao processar o texto: [(,,)]... Erro: invalid syntax (<unknown>, line 1)\n",
            "Texto ignorado: Desculpe, mas parece que houve\n",
            "Triplas salvas no arquivo: projeto_de_nlp/data/triples.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Construção do Gráfico de Conhecimento (KG)"
      ],
      "metadata": {
        "id": "Y4og2A27S03z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código implementa uma série de funções para carregar, construir, salvar e resumir um **grafo de conhecimento (Knowledge Graph - KG)** a partir de um DataFrame contendo triplas no formato (Sujeito, Relacionamento, Objeto). O fluxo geral pode ser descrito assim:\n",
        "\n",
        "1. **Função `load_triples_from_df`**:\n",
        "   - **Objetivo**: Carregar as triplas de um DataFrame. Cada linha do DataFrame representa uma tripla com as colunas `subject`, `relation`, e `object`.\n",
        "   - **Entrada**: DataFrame contendo as triplas.\n",
        "   - **Saída**: Uma lista de tuplas no formato (Sujeito, Relacionamento, Objeto).\n",
        "\n",
        "2. **Função `build_knowledge_graph`**:\n",
        "   - **Objetivo**: Constrói um **grafo de conhecimento** a partir das triplas.\n",
        "   - **Entrada**: Um DataFrame com triplas no formato (Sujeito, Relacionamento, Objeto).\n",
        "   - **Processo**: Utiliza a biblioteca `networkx` para criar um grafo direcionado, onde cada tripla representa uma aresta entre dois nós (sujeito e objeto), e a relação entre eles é armazenada como um atributo da aresta.\n",
        "   - **Saída**: Um grafo direcionado `DiGraph` contendo as triplas.\n",
        "\n",
        "3. **Função `save_knowledge_graph`**:\n",
        "   - **Objetivo**: Salvar o grafo de conhecimento em um arquivo no formato **pickle**.\n",
        "   - **Entrada**: O grafo construído e o caminho de saída onde o grafo será salvo.\n",
        "   - **Saída**: O grafo é salvo no caminho especificado usando pickle para facilitar sua reutilização posterior.\n",
        "\n",
        "4. **Função `summarize_knowledge_graph`**:\n",
        "   - **Objetivo**: Gera um resumo básico do grafo de conhecimento, listando algumas arestas (relações) com os atributos (relações entre os nós).\n",
        "   - **Entrada**: O grafo de conhecimento e o número de amostras de arestas a serem exibidas.\n",
        "   - **Saída**: Exibe no console o número total de nós e arestas no grafo, além de algumas amostras de arestas e suas respectivas relações."
      ],
      "metadata": {
        "id": "e_Bp9XOW05X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_triples_from_df(df):\n",
        "    \"\"\"\n",
        "    Carrega as triplas extraídas de um DataFrame.\n",
        "\n",
        "    Parâmetros:\n",
        "    df (DataFrame): O DataFrame contendo as triplas com as colunas 'subject', 'relation', e 'object'.\n",
        "\n",
        "    Retorno:\n",
        "    List[Tuple]: Uma lista de triplas no formato (Sujeito, Relacionamento, Objeto).\n",
        "    \"\"\"\n",
        "    triples = list(zip(df['subject'], df['relation'], df['object']))\n",
        "    return triples\n",
        "\n",
        "def build_knowledge_graph(df_triples):\n",
        "    \"\"\"\n",
        "    Constrói um gráfico de conhecimento (KG) a partir de uma lista de triplas.\n",
        "\n",
        "    Parâmetros:\n",
        "    triples (List[Tuple]): Lista de triplas no formato (Sujeito, Relacionamento, Objeto).\n",
        "\n",
        "    Retorno:\n",
        "    networkx.DiGraph: Um gráfico direcionado contendo as entidades e suas relações.\n",
        "    \"\"\"\n",
        "    triples = load_triples_from_df(df_triples)\n",
        "\n",
        "    # Criar um gráfico direcionado\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Adicionar triplas ao gráfico\n",
        "    for subject, relation, object_ in triples:\n",
        "        G.add_edge(subject, object_, relation=relation)\n",
        "\n",
        "    return G\n",
        "\n",
        "def save_knowledge_graph(graph, output_path):\n",
        "    \"\"\"\n",
        "    Salva o gráfico de conhecimento (KG) em um arquivo usando pickle.\n",
        "\n",
        "    Parâmetros:\n",
        "    graph (networkx.DiGraph): O gráfico de conhecimento a ser salvo.\n",
        "    output_path (str): Caminho do arquivo onde o gráfico será salvo.\n",
        "    \"\"\"\n",
        "    with open(output_path, 'wb') as f:\n",
        "        pickle.dump(graph, f)\n",
        "    print(f\"Gráfico de conhecimento salvo com sucesso em {output_path}\")\n",
        "\n",
        "def summarize_knowledge_graph(graph, num_samples=5):\n",
        "    \"\"\"\n",
        "    Gera um resumo básico do gráfico de conhecimento, listando algumas arestas com seus atributos.\n",
        "\n",
        "    Parâmetros:\n",
        "    graph (networkx.DiGraph): O gráfico de conhecimento.\n",
        "    num_samples (int): Número de arestas a serem exibidas no resumo.\n",
        "    \"\"\"\n",
        "    print(f\"Total de nós no gráfico: {graph.number_of_nodes()}\")\n",
        "    print(f\"Total de arestas no gráfico: {graph.number_of_edges()}\")\n",
        "\n",
        "    # Mostrar algumas amostras de arestas com seus atributos\n",
        "    sample_edges = list(graph.edges(data=True))[:num_samples]\n",
        "    for u, v, data in sample_edges:\n",
        "        print(f\"{u} --({data['relation']})--> {v}\")"
      ],
      "metadata": {
        "id": "csmN6g0ZSfT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_triples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "Rk7WyfCObGEV",
        "outputId": "27e3bce1-ca77-4420-82fb-38d3aa7373f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               subject  \\\n",
              "0                                           Esta Norma   \n",
              "1                      critérios e parâmetros técnicos   \n",
              "2                                  meio urbano e rural   \n",
              "3                                          edificações   \n",
              "4    diversas condições de mobilidade e de percepçã...   \n",
              "..                                                 ...   \n",
              "762                     Resolução no 738/18 do Contran   \n",
              "763                     Resolução no 303/08 do Contran   \n",
              "764                     Resolução no 236/07 do Contran   \n",
              "765                     Resolução no 304/08 do Contran   \n",
              "766                                         NR 26 − MT   \n",
              "\n",
              "                        relation  \\\n",
              "0                     estabelece   \n",
              "1                   referem-se a   \n",
              "2                  deve observar   \n",
              "3                 devem observar   \n",
              "4        foram consideradas para   \n",
              "..                           ...   \n",
              "762           está relacionada a   \n",
              "763           está relacionada a   \n",
              "764           está relacionada a   \n",
              "765           está relacionada a   \n",
              "766  é uma norma regulamentadora   \n",
              "\n",
              "                                                object  \n",
              "0                      critérios e parâmetros técnicos  \n",
              "1          projeto, construção, instalação e adaptação  \n",
              "2                          condições de acessibilidade  \n",
              "3                          condições de acessibilidade  \n",
              "4    estabelecimento dos critérios e parâmetros téc...  \n",
              "..                                                 ...  \n",
              "762                                 regras de trânsito  \n",
              "763                                 regras de trânsito  \n",
              "764                                 regras de trânsito  \n",
              "765                                 regras de trânsito  \n",
              "766                     sobre sinalização de segurança  \n",
              "\n",
              "[767 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0557479-d8b5-4d8c-b3e9-3ad44f393ca2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>relation</th>\n",
              "      <th>object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Esta Norma</td>\n",
              "      <td>estabelece</td>\n",
              "      <td>critérios e parâmetros técnicos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>critérios e parâmetros técnicos</td>\n",
              "      <td>referem-se a</td>\n",
              "      <td>projeto, construção, instalação e adaptação</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>meio urbano e rural</td>\n",
              "      <td>deve observar</td>\n",
              "      <td>condições de acessibilidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>edificações</td>\n",
              "      <td>devem observar</td>\n",
              "      <td>condições de acessibilidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diversas condições de mobilidade e de percepçã...</td>\n",
              "      <td>foram consideradas para</td>\n",
              "      <td>estabelecimento dos critérios e parâmetros téc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>Resolução no 738/18 do Contran</td>\n",
              "      <td>está relacionada a</td>\n",
              "      <td>regras de trânsito</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>Resolução no 303/08 do Contran</td>\n",
              "      <td>está relacionada a</td>\n",
              "      <td>regras de trânsito</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>Resolução no 236/07 do Contran</td>\n",
              "      <td>está relacionada a</td>\n",
              "      <td>regras de trânsito</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>Resolução no 304/08 do Contran</td>\n",
              "      <td>está relacionada a</td>\n",
              "      <td>regras de trânsito</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>NR 26 − MT</td>\n",
              "      <td>é uma norma regulamentadora</td>\n",
              "      <td>sobre sinalização de segurança</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>767 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0557479-d8b5-4d8c-b3e9-3ad44f393ca2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0557479-d8b5-4d8c-b3e9-3ad44f393ca2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0557479-d8b5-4d8c-b3e9-3ad44f393ca2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d6adc7f-def3-4e84-88e2-a31dff8932aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d6adc7f-def3-4e84-88e2-a31dff8932aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d6adc7f-def3-4e84-88e2-a31dff8932aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_09c07caa-9d2d-4faf-a0bd-9225af373c2f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_triples')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09c07caa-9d2d-4faf-a0bd-9225af373c2f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_triples');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_triples",
              "summary": "{\n  \"name\": \"df_triples\",\n  \"rows\": 767,\n  \"fields\": [\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 587,\n        \"samples\": [\n          \"Escolas\",\n          \"S\\u00edmbolo internacional de pessoas com defici\\u00eancia visual\",\n          \"Piscinas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 331,\n        \"samples\": [\n          \"\\u00e9 uma rampa constru\\u00edda ou implantada na cal\\u00e7ada destinada a promover\",\n          \"admite-se\",\n          \"avan\\u00e7a sob\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"object\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 689,\n        \"samples\": [\n          \"cuja fun\\u00e7\\u00e3o j\\u00e1 est\\u00e1 definida\",\n          \"oferece condi\\u00e7\\u00f5es de uso eficiente e confort\\u00e1vel\",\n          \"1,40 m e 1,50 m\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Resutado do KG\n",
        "\n",
        "O resultado do **grafo de conhecimento** gerado a partir do texto da **NBR9050** foi salvo com sucesso no caminho especificado (`/content/knowledge_graph.gpickle`). O grafo contém **1257 nós** e **763 arestas**, que representam as entidades e suas relações extraídas do texto técnico.\n",
        "\n",
        "Algumas das triplas extraídas e representadas no grafo incluem:\n",
        "1. **Esta Norma** --(estabelece)--> **critérios e parâmetros técnicos**\n",
        "2. **Critérios e parâmetros técnicos** --(referem-se a)--> **projeto, construção, instalação e adaptação**\n",
        "3. **Meio urbano e rural** --(deve observar)--> **condições de acessibilidade**\n",
        "4. **Edificações** --(devem observar)--> **condições de acessibilidade**\n",
        "5. **Diversas condições de mobilidade e de percepção do ambiente** --(foram consideradas para)--> **estabelecimento dos critérios e parâmetros técnicos**\n",
        "\n",
        "Essas triplas representam as principais relações entre os elementos da norma, mapeando as exigências técnicas relacionadas à acessibilidade em projetos e construções. Esse grafo pode ser usado para consultas avançadas sobre acessibilidade e normas técnicas, facilitando a análise e recuperação de informações."
      ],
      "metadata": {
        "id": "MqpQKP0R1QIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir o gráfico de conhecimento\n",
        "knowledge_graph = build_knowledge_graph(df_triples)\n",
        "\n",
        "# Caminho para salvar o gráfico de conhecimento\n",
        "kg_output_path = '/content/knowledge_graph.gpickle'\n",
        "\n",
        "# Salvar o gráfico de conhecimento\n",
        "save_knowledge_graph(knowledge_graph, kg_output_path)\n",
        "\n",
        "# Resumir o gráfico de conhecimento\n",
        "summarize_knowledge_graph(knowledge_graph)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UPFn1JFa2AR",
        "outputId": "9bdefec3-1627-412e-94a5-395df35d2008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gráfico de conhecimento salvo com sucesso em /content/knowledge_graph.gpickle\n",
            "Total de nós no gráfico: 1257\n",
            "Total de arestas no gráfico: 763\n",
            "Esta Norma --(estabelece)--> critérios e parâmetros técnicos\n",
            "critérios e parâmetros técnicos --(referem-se a)--> projeto, construção, instalação e adaptação\n",
            "meio urbano e rural --(deve observar)--> condições de acessibilidade\n",
            "edificações --(devem observar)--> condições de acessibilidade\n",
            "diversas condições de mobilidade e de percepção do ambiente --(foram consideradas para)--> estabelecimento dos critérios e parâmetros técnicos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Visualização Parcial do KG"
      ],
      "metadata": {
        "id": "FPjVzZsA1YWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A imagem mostra uma **visualização interativa** de uma parte do **grafo de conhecimento** que foi gerado a partir das informações extraídas do texto da **NBR9050**. A visualização exibe **200 nós** conectados por arestas, representando entidades e relações extraídas do texto técnico sobre acessibilidade.\n",
        "\n",
        "**Elementos da visualização:**\n",
        "1. **Nós**: Cada nó (representado pelos pontos) corresponde a uma entidade identificada no texto, como \"condições de acessibilidade\", \"dimensões\", ou \"cadeira de rodas\".\n",
        "2. **Arestas**: As conexões entre os nós indicam as relações estabelecidas entre essas entidades, como \"estabelece\", \"refere-se a\", e \"observa\", que mostram como os conceitos estão interligados.\n",
        "3. **Interatividade**: A visualização permite explorar as conexões de maneira mais interativa, com informações sobre as **conexões de cada nó** (indicadas pela legenda de cor à direita), onde nós mais conectados têm uma coloração mais intensa.\n",
        "4. **Legendas**: A barra de cores à direita indica o número de conexões (ou arestas) de cada nó, com o gradiente variando de azul-claro (menor número de conexões) a azul-escuro (maior número de conexões)."
      ],
      "metadata": {
        "id": "wOnUzfgo1zHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_graph_with_plotly(graph, num_nodes=20):\n",
        "    \"\"\"\n",
        "    Visualiza uma amostra do gráfico de conhecimento (KG) usando Plotly para visualização interativa.\n",
        "\n",
        "    Parâmetros:\n",
        "    graph (networkx.DiGraph): O gráfico de conhecimento a ser visualizado.\n",
        "    num_nodes (int): Número de nós a serem exibidos na amostra.\n",
        "    \"\"\"\n",
        "    # Selecionar uma subparte do grafo com num_nodes nós\n",
        "    sampled_graph = graph.subgraph(list(graph.nodes())[:num_nodes])\n",
        "\n",
        "    # Gerar layout (posições dos nós)\n",
        "    pos = nx.spring_layout(sampled_graph, seed=42)\n",
        "\n",
        "    # Extração de arestas\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    for edge in sampled_graph.edges():\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.append(x0)\n",
        "        edge_x.append(x1)\n",
        "        edge_x.append(None)\n",
        "        edge_y.append(y0)\n",
        "        edge_y.append(y1)\n",
        "        edge_y.append(None)\n",
        "\n",
        "    # Desenhar as arestas\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x, y=edge_y,\n",
        "        line=dict(width=1, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines')\n",
        "\n",
        "    # Extração de nós\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "    for node in sampled_graph.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        node_text.append(node)\n",
        "\n",
        "    # Desenhar os nós\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        text=node_text,\n",
        "        hoverinfo='text',\n",
        "        marker=dict(\n",
        "            showscale=True,\n",
        "            colorscale='YlGnBu',\n",
        "            size=10,\n",
        "            colorbar=dict(\n",
        "                thickness=15,\n",
        "                title='Node Connections',\n",
        "                xanchor='left',\n",
        "                titleside='right'\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Criar a figura\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title='<br>Visualização Interativa do Grafo de Conhecimento',\n",
        "                        titlefont_size=16,\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=0, l=0, r=0, t=40),\n",
        "                        annotations=[dict(\n",
        "                            text=\"Interativo com Plotly\",\n",
        "                            showarrow=False,\n",
        "                            xref=\"paper\", yref=\"paper\",\n",
        "                            x=0.005, y=-0.002 )],\n",
        "                        xaxis=dict(showgrid=False, zeroline=False),\n",
        "                        yaxis=dict(showgrid=False, zeroline=False))\n",
        "                   )\n",
        "    fig.show()\n",
        "\n",
        "# Exemplo de visualização de uma amostra do grafo\n",
        "visualize_graph_with_plotly(knowledge_graph, num_nodes=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "DmnzXZ-ndWZu",
        "outputId": "fb8ec779-8048-4baf-8370-8eac6dabfe05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"854b3281-8cdd-4eed-a518-929de505ae1c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"854b3281-8cdd-4eed-a518-929de505ae1c\")) {                    Plotly.newPlot(                        \"854b3281-8cdd-4eed-a518-929de505ae1c\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":1},\"mode\":\"lines\",\"x\":[0.7862838074801594,0.9816748420874277,null,0.4435714549017307,0.6528476947197297,null,0.8087015280749488,0.851940334935584,null,-0.8466680148784971,-0.8953372065817362,null,-0.0892159583800863,-0.08987579853027051,null,0.38415758899493035,0.40738475880189273,null,-0.7386561744953666,-0.9068765246846775,null,0.803432407222396,0.8455391105817123,null,0.13481363259933324,0.14824607815333696,null,-0.6627425193722464,-0.9291375647859369,null,-0.616591440692153,-0.6593468109539965,null,-0.6839500566806374,-0.6518413304964769,null,-0.5885957007434782,-0.6593468109539965,null,0.8068605214409311,0.833876799512489,null,0.8596562996642687,0.9235894723526175,null,-0.9999901706739245,-0.9762630352527202,null,-0.9303217198169821,-0.9698640506536356,null,0.5083106904851061,0.6083346600857892,null,-0.03636815502539304,-0.03610517460057246,null,-0.6474985426621115,-0.9291375647859369,null,0.7677150019997036,0.7390201915867166,null,0.2858418920490869,0.3600926171483489,null,0.033285554576576795,0.024354417390349103,null,0.19890557060283534,0.22663414428389095,null,0.7884816081426954,0.9583286950167895,null,0.7525436250320968,0.9349004216600737,null,0.5149300803077788,0.5435795570522804,null,0.03332551006413212,0.03431285896633237,null,-0.685299325520589,-0.9269098995033609,null,0.8711475102470081,0.908913789554867,null,-0.9776758755166568,-0.9698640506536356,null,-0.4377482105854759,-0.5090361438062482,null,-0.8070595719031537,-0.9124423489689324,null,-0.12312136596819724,-0.1324241019683333,null,-0.19998171915139648,-0.22348392687086652,null,-0.4797015384270691,-0.5158267073865405,null,-0.16370112986780078,-0.17859329713977318,null,0.026174098880743558,-0.5487611137911881,null,0.026174098880743558,0.6015279815802101,null,0.33696095742753257,0.5136376766416295,null,-0.8457483954472832,-0.9735427743298379,null,0.03495145028207661,0.03332551006413212,null,-0.797738279996033,-0.965732791448484,null,0.12363783168022667,0.13780059101222772,null,-0.6518413304964769,-0.866378693150201,null,-0.2809451466701062,-0.3636897649137594,null,-0.7212137682123791,-0.9304888071516425,null,0.6714094700469191,0.6892804104022534,null,-0.5134232692033442,-0.7647390169670905,null,-0.6808198509029402,-0.7776890920638035,null,-0.5293407791686475,-0.5708168895844907,null,-0.00019429262234680743,-0.5950960314441279,null,-0.00019429262234680743,0.9125920792590086,null,-0.00019429262234680743,0.7766352180196918,null,-0.00019429262234680743,0.2968534873887101,null,-0.00019429262234680743,0.3578105290212776,null,-0.00019429262234680743,-0.7640745551189868,null,-0.00019429262234680743,-0.28441646565865447,null,-0.00019429262234680743,-0.08467573743888551,null,-0.00019429262234680743,-0.7846462989720261,null,-0.00019429262234680743,0.5509899814395535,null,-0.00019429262234680743,-0.2874237851112402,null,0.2840803767888423,0.3114236402234033,null,0.9448795505134232,0.9657208511424966,null,0.03451827362373986,0.033285554576576795,null,-0.8661828020489335,-0.9291375647859369,null,-0.5843111100744324,-0.6248791449985472,null,-0.5843111100744324,-0.4461126851378108,null,-0.5843111100744324,-0.6763440932171356,null,0.6760892807061079,0.6437266463352801,null,0.6902118312631051,0.7338029001065417,null,0.01488806214158108,0.01800296128231301,null,-0.849365213175699,-0.9291375647859369,null,0.4580507340378251,0.5769970707166185,null,-0.10879982393744976,-0.08993263337983072,null,-0.4472979038095422,-0.4917405304569929,null,-0.5958351296640418,-0.6854141813651549,null,0.9333857922334554,0.9583286950167895,null,0.47371377544575416,0.5508204779551951,null,0.8595950524551393,0.9449489087011349,null,-0.4902311790659937,-0.6593468109539965,null,0.6323313506584793,0.8467520422970563,null,-0.2925008884002467,-0.3326718668277076,null,0.6004219123120491,0.9583286950167895,null,0.22467074481423283,0.2368132519975625,null,-0.6500137186400404,-0.7649402693150329,null,0.08033207793017454,0.09808649780424822,null,0.8544474416015573,0.9986746635197777,null,0.8397744633089534,0.9677906409263456,null,-0.06276694715123547,-0.07345775051954878,null,-0.8615160288600665,-0.8846722664097646,null,0.5927284665897073,0.8085041088469811,null,-0.4912024062818782,-0.5773187076895625,null,-0.34552811853693144,-0.3789548732224855,null,0.8367804950949754,0.9477033360067246,null,0.7361130536117267,0.9583286950167895,null,0.48195586438341675,0.705786862634225,null,0.5242254273978421,0.5063560286608112,null,0.37778312665662783,0.4435714549017307,null,0.2996689321350073,0.41389861593622446,null,0.28938996827620433,0.3165041578016872,null,-0.7607076087406403,-0.7508757583515987,null,-0.9771793262690631,-0.9344275791191027,null,0.8128752093909444,0.8456711149637377,null,-0.2329846070786463,-0.3636897649137594,null,-0.9489311623237066,-0.9756674923833939,null,-0.6669318988331644,-0.7772578852834752,null,-0.31618222470758856,-0.3789548732224855,null,-0.7245068309502801,-0.9034385615362808,null,0.701747671101991,0.8719011488631506,null,0.7248146569093216,0.9218986305953338,null,-0.12705487117267122,-0.16584776520169542,null,0.35648636217208307,0.46356263217897664,null,-0.3136031065392951,-0.41966997131866224,null],\"y\":[0.08252805253891862,0.09523281833759596,null,-0.479582748711061,-0.7157276028460564,null,0.3312867850159207,0.34880687010409245,null,-0.5660696483083193,-0.5952559780558305,null,-0.9304342993235682,-0.9984690853603929,null,-0.9005656945715468,-0.9146881424089328,null,-0.37437446288476683,-0.44863282423601303,null,-0.4434022277417548,-0.4613344671546507,null,0.911475533124836,1.0,null,0.37118022342316176,0.509630092114957,null,-0.7078990732168969,-0.7481684224955688,null,0.46820198859641726,0.47721791157630244,null,-0.6769646600516004,-0.7481684224955688,null,-0.360900421874943,-0.35529901557250154,null,-0.23471553019080257,-0.24964973417357716,null,-0.04080434408385599,-0.025364027796420927,null,0.3140311743678095,0.34406839114320725,null,-0.7255516925378362,-0.8547907938378829,null,-0.8397431680536095,-0.9297943483439911,null,0.34620552987797487,0.509630092114957,null,0.5160974604392707,0.49753117248434875,null,0.7042092943063801,0.8376472833286223,null,0.8604505957616488,0.8881262557751815,null,0.8303451585171945,0.9384752113527403,null,0.2604725847591834,0.3023792522523724,null,0.020072759745054472,0.03637968713297831,null,0.8178277545184778,0.835792022092548,null,0.7383966453093311,0.9863395273685719,null,0.3003114494118994,0.41101189031609137,null,0.4404838520317612,0.4571657976713066,null,0.2967091342819896,0.34406839114320725,null,0.7360601961302555,0.889262352887937,null,0.2939969602846689,0.3510011443632975,null,0.7598398563655325,0.8869398648097405,null,-0.8635875864805405,-0.9758054693151857,null,-0.7184942991312883,-0.7710465261727217,null,0.8819463437987057,0.9895424919311827,null,-0.7847590894974149,-0.8586628725711005,null,-0.7847590894974149,-0.7142412666990414,null,-0.5962616659713473,-0.8845020419709438,null,0.24908072308225523,0.30721875891595196,null,0.5998555155283114,0.7383966453093311,null,0.030018065133798358,0.04222749918451313,null,-0.895228570533221,-0.9872953413177815,null,0.47721791157630244,0.6403452894665058,null,-0.7554562002684547,-0.9768656202805449,null,-0.10186208023424288,-0.1183632006872361,null,0.7293770391418367,0.7595844039593219,null,0.4940360520340714,0.7675308533954214,null,-0.6012809279737864,-0.6800535908587947,null,0.6023229260431088,0.6597501958200658,null,0.041356374968553176,0.8876475631096518,null,0.041356374968553176,0.136623140389638,null,0.041356374968553176,-0.6354875240358391,null,0.041356374968553176,-0.89037015848857,null,0.041356374968553176,0.924493853595246,null,0.041356374968553176,0.6709911025312252,null,0.041356374968553176,-0.9822685346135952,null,0.041356374968553176,0.9618498019081044,null,0.041356374968553176,-0.5935871271200851,null,0.041356374968553176,-0.7903409876891032,null,0.041356374968553176,0.9728357265242111,null,0.8441245290907007,0.8416310750769791,null,0.21790663782273428,0.2346169090747486,null,0.8025978948962981,0.8604505957616488,null,0.47671217296933366,0.509630092114957,null,0.13945569323986529,-0.8294888179090418,null,0.13945569323986529,0.841253882332644,null,0.13945569323986529,0.797811916917477,null,0.6888649619187622,0.6725115982980305,null,-0.685917892047786,-0.7344216687965514,null,-0.9062645905286972,-0.9968812001035182,null,0.4627308360267556,0.509630092114957,null,0.6040971349778368,0.7409892292850538,null,0.7305098728106658,0.7559800438456026,null,-0.8395489537080524,-0.9163841520897497,null,0.5667267778076419,0.6643447976983339,null,0.3149001948187015,0.3023792522523724,null,0.6929095311290041,0.7885907016167554,null,-0.30097754206899513,-0.3308641691442637,null,-0.5703320269610763,-0.7481684224955688,null,0.4104511793657204,0.5548983621994438,null,-0.7989917247432747,-0.9050504279652956,null,0.19216380856656104,0.3023792522523724,null,-0.9404568850388018,-0.9853153384034448,null,-0.6608915632168088,-0.7728342832418671,null,-0.8050129591125398,-0.9456755216045695,null,-0.1034222259290166,-0.11871740872048403,null,-0.023445522703206365,-0.030749396733232893,null,0.742193510094626,0.8738858726649824,null,-0.3399852962671415,-0.3254975660853807,null,0.4801801612919869,0.6395658779915891,null,0.6492301938141615,0.777920317332066,null,0.8426460357724737,0.9313397164365038,null,-0.1492623651267538,-0.1672330059797672,null,0.2426497607379087,0.3023792522523724,null,0.4047390659101294,0.5942209078650961,null,-0.6426098595809242,-0.6665283037762503,null,-0.40284870629747016,-0.479582748711061,null,0.6409966060545783,0.8395869656406295,null,-0.7383632047826093,-0.798110694928574,null,-0.46622796500782376,-0.4932300438306693,null,-0.20304794903192988,-0.20050265161331088,null,-0.5527095401692012,-0.571369906875822,null,-0.6408023708608729,-0.9768656202805449,null,-0.27818967330415606,-0.26962663196207975,null,0.47062537665837395,0.5589711741811383,null,0.757434014481888,0.9313397164365038,null,0.13507641432806844,0.12424073102071186,null,-0.03588463857749856,-0.04053137200810171,null,-0.35970009623952043,-0.45413884079627004,null,-0.7355260955164206,-0.9637676357478205,null,-0.6634277040668483,-0.8599035141291174,null,-0.6878989411542568,-0.9215347582137502,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"colorbar\":{\"thickness\":15,\"title\":{\"side\":\"right\",\"text\":\"Node Connections\"},\"xanchor\":\"left\"},\"colorscale\":[[0.0,\"rgb(255,255,217)\"],[0.125,\"rgb(237,248,177)\"],[0.25,\"rgb(199,233,180)\"],[0.375,\"rgb(127,205,187)\"],[0.5,\"rgb(65,182,196)\"],[0.625,\"rgb(29,145,192)\"],[0.75,\"rgb(34,94,168)\"],[0.875,\"rgb(37,52,148)\"],[1.0,\"rgb(8,29,88)\"]],\"showscale\":true,\"size\":10},\"mode\":\"markers+text\",\"text\":[\"Figura 4\",\"Sinalização de segurança contra incêndio e pânico\",\"módulo de referência\",\"Figura 1\",\"Aparelho sanitário de material cerâmico\",\"0,25 a 0,33\",\"ABNT NBR 13434\",\"área de transferência\",\"0,75 m\",\"ABNT NBR 13713\",\"ABNT NBR 16537\",\"0,95 m\",\"Figura 3\",\"crianças em cadeiras de rodas infantis\",\"Saídas de emergência em edifícios\",\"Figura 6\",\"Instalação suspensa\",\"aparelhos de apoio\",\"0,80 m para extensão de no máximo 0,40 m\",\"1,20 m × 1,20 m\",\"Muletas tipo canadense\",\"Largura para transposição de obstáculos isolados\",\"Graus de proteção para invólucros de equipamentos elétricos\",\"Sem órtese\",\"Rotação de 90°\",\"à implantação de mobiliário, sinalização, vegetação, placas de sinalização e outros fins\",\"ABNT NBR 10898\",\"medidas entre 5 % a 95 % da população brasileira\",\"Um pedestre e uma pessoa em cadeira de rodas\",\"Uma pessoa em cadeira de rodas\",\"calçada rebaixada\",\"possibilidades que dispensam a instalação de sinalização tátil e visual de alerta\",\"área de aproximação\",\"0,60 a 0,70\",\"0,71 a 0,73\",\"próteses\",\"aparelhos específicos para mobilidade\",\"Figura 8\",\"Acessibilidade em caixa de autoatendimento bancário\",\"altura entre 0,60 m até 2,10 m do piso\",\"ABNT NBR 11785\",\"0,33\",\"ABNT NBR 15097\",\"pessoas em cadeira de rodas\",\"na projeção de um mobiliário suspenso\",\"critérios e parâmetros técnicos\",\"0,40 a 0,46\",\"ABNT NBR 5410\",\"1,00 m\",\"transferência por pessoa com deficiência ou mobilidade reduzida\",\"0,90 m\",\"Piscinas – Projeto, execução e manutenção\",\"0,30 a 0,40\",\"adaptado\",\"projeção de 0,80 m por 1,20 m no piso\",\"ABNT NBR 15599\",\"estabelecimento dos critérios e parâmetros técnicos\",\"espaços, edificações, mobiliários e equipamentos urbanos acessíveis\",\"dimensões referenciais\",\"contraste\",\"calçada\",\"1,20 m\",\"linha do horizonte\",\"ao disposto nesta Norma\",\"Duas bengalas\",\"Níveis de ruído para conforto acústico\",\"Área de circulação e manobra\",\"2,10 m x 0,80 m\",\"Duas pessoas em cadeira de rodas\",\"1,5 cm\",\"0,85 m\",\"manobra, deslocamento e aproximação de todas as pessoas\",\"Revestimentos eletrolíticos de metais e plásticos sanitários\",\"a funcionalidade relacionada à atividade e à participação da pessoa com deficiência ou mobilidade reduzida\",\"Mobiliário\",\"Mobiliários\",\"acessibilidade\",\"acessíveis em suas áreas de uso comum\",\"pessoa com mobilidade reduzida\",\"mais de 0,10 m de profundidade\",\"Referências normativas\",\"transposição de obstáculo isolado\",\"ABNT NBR 15250\",\"área de descanso\",\"usuários que necessitem de paradas temporárias\",\"Parâmetros antropométricos\",\"0,10 m x 0,90 m x 1,20 m\",\"parâmetros\",\"sanitário\",\"Measurement of light reflectance value and small color differences between pieces of ceramic tile\",\"Figura 5\",\"rota acessível\",\"Guarda-corpos para edificação\",\"área de circulação\",\"0,42 a 0,45\",\"1,20 m x 0,80 m\",\"Mobiliários na rota acessível\",\"alcance, percepção e entendimento para utilização\",\"0,93\",\"unidades autônomas acessíveis\",\"Acessibilidade – Sinalização tátil no piso\",\"subseção da norma\",\"Largura da roda\",\"M.R.\",\"adaptável\",\"1,50 m × 1,20 m\",\"Dimensões em metros\",\"0,07\",\"Rotação de 180°\",\"Instalações elétricas de baixa tensão\",\"Barra antipânico\",\"utilização autônoma, independente e segura\",\"0,49 a 0,53\",\"P.O.\",\"Esta Norma\",\"Acessibilidade – Comunicação na prestação de serviços\",\"Plataformas de elevação motorizadas para pessoas com mobilidade reduzida\",\"cadeiras de rodas\",\"todas as pessoas\",\"Módulo de referência (M.R.)\",\"Proteção lateral\",\"ASTM C609-07\",\"dimensões referenciais para transposição por pessoas em cadeiras de rodas\",\"documentos relacionados\",\"medidas necessárias para manobra de cadeira de rodas\",\"pessoas com deficiências visuais\",\"ABNT NBR NM 313\",\"bengalas de rastreamento\",\"pessoa obesa\",\"bacia sanitária, lavatório, espelho e demais acessórios\",\"0,60 m acima do piso\",\"Manobra de cadeiras de rodas com deslocamento\",\"Cadeira de rodas\",\"desde o piso\",\"ABNT NBR 10283\",\"ABNT NBR IEC 60529\",\"adequado\",\"banheiro\",\"Cão-guia\",\"Apoio de tripé\",\"dimensões referenciais para deslocamento\",\"Instalações hidráulicas prediais – Aparelhos automáticos acionados mecanicamente\",\"diversas condições de mobilidade e de percepção do ambiente\",\"Figura 2\",\"ABNT NBR 10152\",\"áreas técnicas de serviço ou de acesso restrito\",\"Sistema de iluminação de emergência\",\"1,50 a 1,80 m\",\"ABNT NBR 9077\",\"Rotação de 360°\",\"Bengala longa\",\"projeto, construção, instalação e adaptação\",\"área de refúgio ou resgate\",\"Borda ou saliência detectável com bengala longa\",\"extremos\",\"Andador rígido\",\"Figura 7\",\"Saliências\",\"Tintas – Determinação da aderência\",\"Dimensões do módulo de referência (M.R.)\",\"edificações\",\"0,90 m para extensão acima de 0,40 m\",\"acessíveis\",\"sistemas assistivos de audição\",\"espaços, mobiliários, equipamentos urbanos, edificações, transportes, informação e comunicação\",\"uma pessoa utilizando cadeira de rodas motorizadas ou não\",\"Largura para deslocamento em linha reta\",\"1,50 m\",\"ABNT NBR ISO 9386\",\"Elevadores de passageiros – Requisitos de segurança para construção e instalação\",\"Pessoas em pé\",\"1,20 a 1,50 m\",\"mulheres de baixa estatura e homens de estatura elevada\",\"P.M.R.\",\"Cadeira de rodas esportivas ou cambadas\",\"0,95 a 1,15\",\"manobra sem deslocamento\",\"ABNT NBR 10339\",\"L.H.\",\"dimensões referenciais para deslocamento em linha reta\",\"diferença mínima em valor de reflexão da luz (LRV) de 30 pontos\",\"espaço\",\"Andador com rodas\",\"desenho universal\",\"ambiente, edificações, mobiliário, equipamentos urbanos e elementos\",\"ABNT NBR 14718\",\"visual, tátil ou sonora\",\"meio urbano e rural\",\"a concordância de nível entre esta e o leito carroçável\",\"Uma bengala\",\"ajuda técnica\",\"edificações residenciais multifamiliares, condomínios e conjuntos habitacionais\",\"chuveiro ou chuveiro e banheira, bacia sanitária, lavatório, espelho e demais acessórios\",\"0,60 m\",\"ABNT NBR 11003\",\"pessoas com deficiência ou com mobilidade reduzida\",\"Área para manobra de cadeiras de rodas\",\"condições de acessibilidade\",\"aparelhos específicos para percepção\",\"Muletas\"],\"x\":[0.7862838074801594,0.851940334935584,-0.7776890920638035,0.4435714549017307,0.3600926171483489,-0.7647390169670905,0.8087015280749488,-0.8466680148784971,-0.9034385615362808,-0.0892159583800863,0.38415758899493035,-0.8846722664097646,-0.7386561744953666,-0.965732791448484,0.2368132519975625,0.803432407222396,0.13481363259933324,-0.6627425193722464,-0.5487611137911881,0.833876799512489,-0.616591440692153,-0.6839500566806374,-0.6854141813651549,-0.5885957007434782,0.8068605214409311,0.908913789554867,0.8596562996642687,0.03431285896633237,-0.9999901706739245,-0.9303217198169821,0.5083106904851061,0.8455391105817123,-0.03636815502539304,-0.7640745551189868,-0.5950960314441279,-0.6474985426621115,-0.9291375647859369,0.5769970707166185,0.5136376766416295,-0.22348392687086652,0.7677150019997036,-0.28441646565865447,0.2858418920490869,0.705786862634225,0.9677906409263456,0.033285554576576795,0.9125920792590086,0.19890557060283534,0.3165041578016872,-0.8953372065817362,-0.9698640506536356,-0.7508757583515987,0.7766352180196918,0.7884816081426954,-0.6248791449985472,0.7525436250320968,0.8467520422970563,0.5149300803077788,0.03332551006413212,-0.685299325520589,0.8711475102470081,-0.41966997131866224,-0.9344275791191027,0.5435795570522804,-0.9776758755166568,-0.3326718668277076,-0.4377482105854759,0.9449489087011349,-0.8070595719031537,-0.2874237851112402,0.8456711149637377,-0.03610517460057246,-0.4917405304569929,0.8719011488631506,-0.12312136596819724,-0.19998171915139648,-0.4797015384270691,0.9218986305953338,0.41389861593622446,-0.5773187076895625,-0.16370112986780078,0.026174098880743558,0.33696095742753257,-0.8457483954472832,-0.9735427743298379,0.03495145028207661,0.09808649780424822,-0.797738279996033,0.12363783168022667,0.7338029001065417,-0.6518413304964769,0.6892804104022534,-0.7772578852834752,-0.2809451466701062,0.2968534873887101,-0.6763440932171356,-0.7212137682123791,-0.5158267073865405,0.3578105290212776,0.6714094700469191,0.40738475880189273,-0.5090361438062482,-0.5134232692033442,-0.6808198509029402,-0.5293407791686475,0.3114236402234033,-0.00019429262234680743,0.5509899814395535,0.2840803767888423,0.22663414428389095,0.7390201915867166,-0.9756674923833939,-0.7846462989720261,0.9448795505134232,0.03451827362373986,0.9349004216600737,0.5063560286608112,-0.8661828020489335,-0.3636897649137594,-0.5843111100744324,0.6760892807061079,0.6902118312631051,-0.866378693150201,-0.17859329713977318,0.8085041088469811,-0.9304888071516425,0.01488806214158108,-0.849365213175699,0.9657208511424966,0.13780059101222772,0.14824607815333696,0.4580507340378251,-0.10879982393744976,0.6437266463352801,-0.4472979038095422,-0.5958351296640418,0.9333857922334554,0.47371377544575416,0.8595950524551393,-0.4902311790659937,0.6528476947197297,-0.08987579853027051,0.6323313506584793,-0.08993263337983072,-0.2925008884002467,0.6004219123120491,0.9235894723526175,-0.9124423489689324,0.22467074481423283,-0.6500137186400404,0.08033207793017454,0.024354417390349103,0.8544474416015573,0.8397744633089534,-0.06276694715123547,-0.8615160288600665,0.5927284665897073,-0.4912024062818782,-0.16584776520169542,-0.9068765246846775,-0.34552811853693144,0.6015279815802101,0.9583286950167895,0.8367804950949754,0.7361130536117267,-0.4461126851378108,0.48195586438341675,-0.7649402693150329,0.5242254273978421,0.01800296128231301,0.37778312665662783,-0.9762630352527202,-0.07345775051954878,0.2996689321350073,0.28938996827620433,-0.08467573743888551,0.46356263217897664,-0.7607076087406403,-0.9771793262690631,0.9816748420874277,-0.1324241019683333,-0.5708168895844907,0.8128752093909444,-0.2329846070786463,-0.9489311623237066,-0.6669318988331644,-0.9269098995033609,-0.31618222470758856,0.6083346600857892,-0.7245068309502801,0.701747671101991,0.7248146569093216,0.5508204779551951,-0.6593468109539965,-0.12705487117267122,0.9986746635197777,0.35648636217208307,-0.3789548732224855,0.9477033360067246,-0.3136031065392951],\"y\":[0.08252805253891862,0.34880687010409245,-0.6800535908587947,-0.479582748711061,0.8376472833286223,0.7675308533954214,0.3312867850159207,-0.5660696483083193,0.12424073102071186,-0.9304342993235682,-0.9005656945715468,-0.3254975660853807,-0.37437446288476683,0.04222749918451313,-0.9853153384034448,-0.4434022277417548,0.911475533124836,0.37118022342316176,-0.8586628725711005,-0.35529901557250154,-0.7078990732168969,0.46820198859641726,0.6643447976983339,-0.6769646600516004,-0.360900421874943,0.4571657976713066,-0.23471553019080257,0.9863395273685719,-0.04080434408385599,0.3140311743678095,-0.7255516925378362,-0.4613344671546507,-0.8397431680536095,0.6709911025312252,0.8876475631096518,0.34620552987797487,0.509630092114957,0.7409892292850538,-0.8845020419709438,-0.9758054693151857,0.5160974604392707,-0.9822685346135952,0.7042092943063801,0.5942209078650961,-0.030749396733232893,0.8604505957616488,0.136623140389638,0.8303451585171945,-0.798110694928574,-0.5952559780558305,0.34406839114320725,-0.4932300438306693,-0.6354875240358391,0.2604725847591834,-0.8294888179090418,0.020072759745054472,0.5548983621994438,0.8178277545184778,0.7383966453093311,0.3003114494118994,0.4404838520317612,-0.9215347582137502,-0.20050265161331088,0.835792022092548,0.2967091342819896,-0.9050504279652956,0.7360601961302555,-0.3308641691442637,0.2939969602846689,0.9728357265242111,-0.571369906875822,-0.9297943483439911,-0.9163841520897497,-0.04053137200810171,0.7598398563655325,-0.8635875864805405,-0.7184942991312883,-0.45413884079627004,0.8395869656406295,0.777920317332066,0.8819463437987057,-0.7847590894974149,-0.5962616659713473,0.24908072308225523,0.30721875891595196,0.5998555155283114,-0.9456755216045695,0.030018065133798358,-0.895228570533221,-0.7344216687965514,0.47721791157630244,0.7595844039593219,0.5589711741811383,-0.7554562002684547,-0.89037015848857,0.797811916917477,-0.10186208023424288,-0.7710465261727217,0.924493853595246,0.7293770391418367,-0.9146881424089328,0.889262352887937,0.4940360520340714,-0.6012809279737864,0.6023229260431088,0.8416310750769791,0.041356374968553176,-0.7903409876891032,0.8441245290907007,0.9384752113527403,0.49753117248434875,-0.26962663196207975,-0.5935871271200851,0.21790663782273428,0.8025978948962981,0.03637968713297831,-0.6665283037762503,0.47671217296933366,-0.9768656202805449,0.13945569323986529,0.6888649619187622,-0.685917892047786,0.6403452894665058,0.9895424919311827,0.6395658779915891,-0.1183632006872361,-0.9062645905286972,0.4627308360267556,0.2346169090747486,-0.9872953413177815,1.0,0.6040971349778368,0.7305098728106658,0.6725115982980305,-0.8395489537080524,0.5667267778076419,0.3149001948187015,0.6929095311290041,-0.30097754206899513,-0.5703320269610763,-0.7157276028460564,-0.9984690853603929,0.4104511793657204,0.7559800438456026,-0.7989917247432747,0.19216380856656104,-0.24964973417357716,0.3510011443632975,-0.9404568850388018,-0.6608915632168088,-0.8050129591125398,0.8881262557751815,-0.1034222259290166,-0.023445522703206365,0.742193510094626,-0.3399852962671415,0.4801801612919869,0.6492301938141615,-0.9637676357478205,-0.44863282423601303,0.8426460357724737,-0.7142412666990414,0.3023792522523724,-0.1492623651267538,0.2426497607379087,0.841253882332644,0.4047390659101294,-0.7728342832418671,-0.6426098595809242,-0.9968812001035182,-0.40284870629747016,-0.025364027796420927,0.8738858726649824,0.6409966060545783,-0.7383632047826093,0.9618498019081044,-0.8599035141291174,-0.46622796500782376,-0.20304794903192988,0.09523281833759596,0.8869398648097405,0.6597501958200658,-0.5527095401692012,-0.6408023708608729,-0.27818967330415606,0.47062537665837395,0.41101189031609137,0.757434014481888,-0.8547907938378829,0.13507641432806844,-0.03588463857749856,-0.35970009623952043,0.7885907016167554,-0.7481684224955688,-0.7355260955164206,-0.11871740872048403,-0.6634277040668483,0.9313397164365038,-0.1672330059797672,-0.6878989411542568],\"type\":\"scatter\"}],                        {\"annotations\":[{\"showarrow\":false,\"text\":\"Interativo com Plotly\",\"x\":0.005,\"xref\":\"paper\",\"y\":-0.002,\"yref\":\"paper\"}],\"hovermode\":\"closest\",\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":40},\"showlegend\":false,\"title\":{\"font\":{\"size\":16},\"text\":\"\\u003cbr\\u003eVisualização Interativa do Grafo de Conhecimento\"},\"xaxis\":{\"showgrid\":false,\"zeroline\":false},\"yaxis\":{\"showgrid\":false,\"zeroline\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('854b3281-8cdd-4eed-a518-929de505ae1c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Implementação do Sistema de Perguntas e Respostas (KG-RAG)"
      ],
      "metadata": {
        "id": "sEm0k-c8SveB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Implementação do Sistema de Perguntas e Respostas (KG-RAG)** envolve o uso de um **Gráfico de Conhecimento** (Knowledge Graph) integrado com um modelo de linguagem, como o Sabia-3. O gráfico organiza informações em entidades (nós) e suas relações, que são usadas para recuperar dados estruturados. Quando uma pergunta é feita, o sistema consulta o gráfico para encontrar informações relevantes e combina essas informações com a capacidade do modelo de gerar texto, resultando em respostas mais precisas e contextualizadas. O **KG-RAG** aumenta a precisão das respostas, baseando-se em dados específicos, ao contrário do baseline, que apenas usa conhecimento não estruturado."
      ],
      "metadata": {
        "id": "jktlVE19_iNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_with_accessibility_knowledge(question, graph, model=\"sabia-3\", info_limit=20):\n",
        "    \"\"\"\n",
        "    Extrai conhecimento relevante do gráfico de conhecimento com base em uma questão,\n",
        "    verificando se cada nó é relevante utilizando o modelo Sabia-3 da Maritaca.\n",
        "\n",
        "    Parâmetros:\n",
        "    - question (str): O enunciado da questão para o qual queremos encontrar informações relacionadas.\n",
        "    - graph (networkx.DiGraph): O gráfico de conhecimento a ser consultado.\n",
        "    - model (str): O modelo Sabia-3 da Maritaca a ser utilizado.\n",
        "    - info_limit (int): Limite do número de informações relevantes a serem retornadas.\n",
        "\n",
        "    Retorno:\n",
        "    - str: Informações relevantes recuperadas do gráfico, ou 'Nenhuma informação relevante encontrada'.\n",
        "    \"\"\"\n",
        "\n",
        "    def filter_relevant_nodes(nodes):\n",
        "        \"\"\"\n",
        "        Filtra os nós relevantes de uma só vez utilizando o Sabia-3 para identificar\n",
        "        quais nós são úteis como base de conhecimento.\n",
        "\n",
        "        Parâmetros:\n",
        "        - nodes (list): Lista de nós do gráfico para serem avaliados.\n",
        "\n",
        "        Retorno:\n",
        "        - list: Lista de nós considerados relevantes pelo Sabia-3.\n",
        "        \"\"\"\n",
        "        # Criar o prompt template para o LangChain\n",
        "        prompt_template = PromptTemplate(\n",
        "            input_variables=[\"nodes\"],\n",
        "            template=\"\"\"\n",
        "            A seguir estão os nós de um gráfico de conhecimento técnico. Indique quais são relevantes e úteis como base de conhecimento para um sistema de perguntas e respostas sobre acessibilidade.\n",
        "\n",
        "            Nós:\n",
        "            {nodes}\n",
        "\n",
        "            Para cada nó, responda apenas \"Sim\" se ele for relevante, ou \"Não\" se ele não for.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Formatar o prompt\n",
        "        nodes_str = \"\\n\".join(nodes)\n",
        "        formatted_prompt = prompt_template.format(nodes=nodes_str)\n",
        "\n",
        "        # Configuração da API da Maritaca para autenticação e uso do modelo Sabia-3\n",
        "        api_key = configure_maritaca()\n",
        "        model_instance = maritalk.MariTalk(key=api_key, model=model)\n",
        "\n",
        "        # Criar a cadeia LLM com o LangChain\n",
        "        llm_chain = LLMChain(\n",
        "            llm=model_instance,\n",
        "            prompt=formatted_prompt\n",
        "        )\n",
        "\n",
        "        # Geração da resposta usando o LangChain\n",
        "        response = llm_chain.run()\n",
        "\n",
        "        # Processar a resposta do Sabia-3\n",
        "        answer = response.strip().splitlines()\n",
        "\n",
        "        # Filtrar os nós considerados relevantes (\"Sim\")\n",
        "        relevant_nodes = [node for node, answer_line in zip(nodes, answer) if answer_line.upper() == \"SIM\"]\n",
        "\n",
        "        return relevant_nodes\n",
        "\n",
        "    # Obter todos os nós do gráfico\n",
        "    all_nodes = list(graph.nodes)\n",
        "\n",
        "    # Filtrar os nós relevantes usando Sabia-3 através do LangChain\n",
        "    relevant_nodes = filter_relevant_nodes(all_nodes)\n",
        "\n",
        "    # Lista para armazenar o conhecimento relevante\n",
        "    relevant_knowledge = []\n",
        "    count = 0\n",
        "\n",
        "    # Iterar sobre os nós relevantes e extrair conexões\n",
        "    for node in relevant_nodes:\n",
        "        for neighbor in graph.neighbors(node):\n",
        "            if count >= info_limit:\n",
        "                break\n",
        "            edge_data = graph.get_edge_data(node, neighbor)\n",
        "            relacao = edge_data.get('relation') if edge_data else \"sem relação definida\"\n",
        "            relevant_knowledge.append(f\"{node} está relacionado a {neighbor} através de {relacao}.\")\n",
        "            count += 1\n",
        "\n",
        "    # Se algum conhecimento relevante foi encontrado, retornar o resultado\n",
        "    return \"\\n\".join(relevant_knowledge) if relevant_knowledge else \"Nenhuma informação relevante encontrada.\"\n"
      ],
      "metadata": {
        "id": "hsKwu31rSfJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Função principal (`augment_with_accessibility_knowledge`)**: Lida com a questão inicial, consulta o gráfico de conhecimento e retorna as informações relevantes. Ela usa o modelo Sabia-3 da Maritaca para validar a relevância dos nós do gráfico.\n",
        "   \n",
        "2. **Função interna (`filter_relevant_nodes`)**: Faz o trabalho de triagem dos nós, utilizando um modelo de linguagem natural para determinar se cada nó do gráfico é relevante ou não para a questão.\n",
        "\n",
        "### Fluxo do Processo:\n",
        "- A função começa extraindo todos os nós do gráfico.\n",
        "- Filtra esses nós usando o modelo Sabia-3 da Maritaca.\n",
        "- Em seguida, coleta informações sobre as conexões desses nós, limitando a quantidade de informações retornadas pelo parâmetro `info_limit`.\n",
        "- O retorno é uma string com as informações relevantes ou uma mensagem padrão se nenhuma informação for encontrada."
      ],
      "metadata": {
        "id": "zaE9sZFo3QlM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1. Perguntas"
      ],
      "metadata": {
        "id": "F7MwwYyTywVL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coleta das perguntas foi feita utilizando o Python para processar o HTML das páginas, analisando sua estrutura e extraindo informações específicas como enunciado, alternativas e respostas corretas. Aqui está o detalhamento do processo:\n"
      ],
      "metadata": {
        "id": "97mi81HP8Pgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6.1.1 Carregamento do HTML\n",
        "Primeiro, carregamos os arquivos HTML das páginas do site, que você forneceu, utilizando a função `BeautifulSoup` da biblioteca `bs4`. O BeautifulSoup é uma ferramenta poderosa que nos permite fazer parsing de documentos HTML e XML, facilitando a navegação e extração de dados.\n"
      ],
      "metadata": {
        "id": "jFjB6g2yJaTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6.1.2 Identificação das Estruturas HTML\n",
        "Com base na análise das páginas HTML que você enviou, percebemos que:\n",
        "- **Enunciado**: As perguntas estavam em uma `div` com a classe `q-question-enunciation`. O enunciado das perguntas está dentro de um atributo `aria-label`.\n",
        "- **Alternativas**: As alternativas estão dentro de `label` com a classe `q-radio-button js-choose-alternative`. Cada alternativa tem um input com um valor (`value`) que indica a letra (A, B, C, etc.), e o conteúdo da alternativa é encontrado dentro de uma `div` com a classe `q-item-enum js-alternative-content`.\n",
        "- **Respostas corretas**: As respostas corretas estavam dentro de um `fieldset` com a classe `q-questions-feedback`. Para cada resposta, temos um índice (`q-index`) que corresponde ao número da questão, e a resposta correta estava dentro de um `span` com a classe `q-answer`.\n"
      ],
      "metadata": {
        "id": "j1cOYnkQJfo_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6.1.3 **Extração de Dados**\n",
        "#### a. **Extração do Enunciado e Alternativas**\n",
        "Cada `div` com a classe `js-question-item` foi utilizada para encontrar o enunciado e as alternativas de uma questão. Para cada questão:\n",
        "- **Enunciado**: Extraímos o valor do atributo `aria-label` da `div` com a classe `q-question-enunciation`.\n",
        "- **Alternativas**: Iteramos sobre cada `label` dentro da questão para coletar a letra da alternativa (do `value` do input) e o conteúdo da alternativa (da `div` com a classe `q-item-enum js-alternative-content`).\n",
        "\n",
        "#### b. **Extração das Respostas Corretas**\n",
        "As respostas corretas foram extraídas de uma estrutura de feedback (`q-feedback`) onde, para cada questão, tínhamos o índice da questão (`q-index`) e a resposta correta associada a esse índice (`q-answer`).\n",
        "\n",
        "### 6.1.4 **Combinação de Perguntas e Respostas**\n",
        "Após extrair todas as perguntas e respostas, associamos as perguntas às suas respectivas respostas corretas utilizando o índice da questão (`q-index`). Isso garantiu que cada pergunta fosse associada à resposta correta.\n"
      ],
      "metadata": {
        "id": "E9-IAiPFJg_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6.1.5 **Criação de um DataFrame**\n",
        "Uma vez que os dados foram extraídos e combinados, converti todas as informações em um `DataFrame` do pandas, que permite uma visualização organizada das perguntas, alternativas e respostas corretas.\n"
      ],
      "metadata": {
        "id": "QfcygmMNJjJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6.1.6 **Exportação para CSV**\n",
        "Finalmente, o DataFrame foi exportado para um arquivo CSV para que você pudesse fazer o download e análise das questões em uma planilha."
      ],
      "metadata": {
        "id": "Xb4JRX6fJkgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Function to load HTML content from a file and parse it with BeautifulSoup\n",
        "def load_html(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    return BeautifulSoup(content, 'html.parser')\n",
        "\n",
        "# Function to extract questions, alternatives, and index (q-index)\n",
        "def extract_questions(soup):\n",
        "    questions_data = []\n",
        "    questions = soup.find_all('div', class_='js-question-item')\n",
        "    for question in questions:\n",
        "        # Extract the question index (q-index)\n",
        "        q_index = question.find('span', class_='q-index').get_text(strip=True)\n",
        "\n",
        "        # Extract the question statement\n",
        "        enunciado = question.find('div', class_='q-question-enunciation').get('aria-label', '').strip()\n",
        "\n",
        "        # Extract the alternatives\n",
        "        alternatives = question.find_all('label', class_='q-radio-button js-choose-alternative')\n",
        "        options = []\n",
        "        for alternative in alternatives:\n",
        "            letter = alternative.find('input')['value']  # Get the letter (A, B, C, etc.)\n",
        "            content = alternative.find('div', class_='q-item-enum js-alternative-content').get_text(strip=True)  # Get the content\n",
        "            options.append(f\"{letter}: {content}\")\n",
        "\n",
        "        questions_data.append({\n",
        "            'q_index': q_index,\n",
        "            'enunciado': enunciado,\n",
        "            'alternatives': options\n",
        "        })\n",
        "\n",
        "    return questions_data\n",
        "\n",
        "# Function to extract correct answers based on the index (q-index)\n",
        "def extract_answers(soup):\n",
        "    answers_data = []\n",
        "    feedback_items = soup.find_all('div', class_='q-feedback')\n",
        "    for feedback in feedback_items:\n",
        "        q_index = feedback.find('span', class_='q-index').get_text(strip=True).replace(\":\", \"\")  # Remove the \":\" from the index\n",
        "        correct_answer = feedback.find('span', class_='q-answer').get_text(strip=True)  # Extract the correct answer\n",
        "        answers_data.append({\n",
        "            'q_index': q_index,\n",
        "            'correct_answer': correct_answer\n",
        "        })\n",
        "\n",
        "    return answers_data\n",
        "\n",
        "# Function to combine questions and answers based on q_index\n",
        "def combine_questions_and_answers(questions, answers):\n",
        "    combined_data = []\n",
        "    for question in questions:\n",
        "        # Find the correct answer by q_index\n",
        "        correct_answer = next((answer['correct_answer'] for answer in answers if answer['q_index'] == question['q_index']), None)\n",
        "        question['correct_answer'] = correct_answer\n",
        "        combined_data.append(question)\n",
        "\n",
        "    return combined_data\n",
        "\n",
        "# Load the HTML files\n",
        "file1 = \"/projeto_de_nlp/data/Questões de Provas - Questões de Concursos Qconcursos.com.html\"\n",
        "file2 = \"/projeto_de_nlp/data/Questões de Provas - Questões de Concursos - Página 2 Qconcursos.com.html\"\n",
        "file3 = \"/projeto_de_nlp/data/Questões de Provas - Questões de Concursos - Página 3 Qconcursos.com.html\"\n",
        "\n",
        "soup1 = load_html(file1)\n",
        "soup2 = load_html(file2)\n",
        "soup3 = load_html(file3)\n",
        "\n",
        "# Extract questions and answers from each file\n",
        "questions_file1 = extract_questions(soup1)\n",
        "answers_file1 = extract_answers(soup1)\n",
        "\n",
        "questions_file2 = extract_questions(soup2)\n",
        "answers_file2 = extract_answers(soup2)\n",
        "\n",
        "questions_file3 = extract_questions(soup3)\n",
        "answers_file3 = extract_answers(soup3)\n",
        "\n",
        "# Combine all questions and answers\n",
        "combined_file1 = combine_questions_and_answers(questions_file1, answers_file1)\n",
        "combined_file2 = combine_questions_and_answers(questions_file2, answers_file2)\n",
        "combined_file3 = combine_questions_and_answers(questions_file3, answers_file3)\n",
        "\n",
        "# Combine all data into a single list\n",
        "all_combined_data = combined_file1 + combined_file2 + combined_file3\n",
        "\n",
        "# Convert the combined data into a DataFrame\n",
        "combined_df = pd.DataFrame(all_combined_data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_file_path = \"/projeto_de_nlp/data/questions_report.csv\"\n",
        "combined_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Provide the link to download the CSV file\n",
        "csv_file_path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_u4lNAZQ9JGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Definir o caminho do arquivo no Google Drive\n",
        "csv_file_path = '/content/drive/My Drive/questions_report.csv'\n",
        "\n",
        "# Carregar o arquivo CSV em um DataFrame do pandas\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Função para converter as strings para listas\n",
        "df['alternatives'] = df['alternatives'].apply(ast.literal_eval)\n",
        "\n",
        "# Criar a coluna 'pesos' que conta quantas alternativas há em cada questão\n",
        "df['pesos'] = df['alternatives'].apply(len)\n",
        "\n",
        "# Exibir o DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "aTzqvXsH1hVi",
        "outputId": "6a9d6722-ccb6-40b2-b91f-f85ec6613ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   q_index                                          enunciado  \\\n",
              "0        1  De acordo com o que estabelece a ABNT NBR 9050...   \n",
              "1        2  De acordo com as normas de acessibilidade para...   \n",
              "2        3  A norma brasileira NBR 9050:2015 estabelece os...   \n",
              "3        4  De acordo com a ABNT NBR 9050:2020 -\\nAcessibi...   \n",
              "4        5  Considerando-se a definição de Módulo de Refer...   \n",
              "\n",
              "                                        alternatives correct_answer  pesos  \n",
              "0  [A: 0,90m, B: 1,20m, C: 1,50m, D: 1,80m, E: 2,...              B      5  \n",
              "1  [A: Quando houver degraus ou escadas em rotas ...              E      5  \n",
              "2  [A: os postos de saúde que comportam internaçõ...              C      4  \n",
              "3  [A: Considera-se o módulo de referência para p...              C      4  \n",
              "4  [A: 0,60m | 1,20m, B: 0,80m | 1,10m, C: 0,90m ...              E      5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39845dba-1ffb-43de-9f93-01e9be80ea44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q_index</th>\n",
              "      <th>enunciado</th>\n",
              "      <th>alternatives</th>\n",
              "      <th>correct_answer</th>\n",
              "      <th>pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>De acordo com o que estabelece a ABNT NBR 9050...</td>\n",
              "      <td>[A: 0,90m, B: 1,20m, C: 1,50m, D: 1,80m, E: 2,...</td>\n",
              "      <td>B</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>De acordo com as normas de acessibilidade para...</td>\n",
              "      <td>[A: Quando houver degraus ou escadas em rotas ...</td>\n",
              "      <td>E</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>A norma brasileira NBR 9050:2015 estabelece os...</td>\n",
              "      <td>[A: os postos de saúde que comportam internaçõ...</td>\n",
              "      <td>C</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>De acordo com a ABNT NBR 9050:2020 -\\nAcessibi...</td>\n",
              "      <td>[A: Considera-se o módulo de referência para p...</td>\n",
              "      <td>C</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Considerando-se a definição de Módulo de Refer...</td>\n",
              "      <td>[A: 0,60m | 1,20m, B: 0,80m | 1,10m, C: 0,90m ...</td>\n",
              "      <td>E</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39845dba-1ffb-43de-9f93-01e9be80ea44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39845dba-1ffb-43de-9f93-01e9be80ea44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39845dba-1ffb-43de-9f93-01e9be80ea44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7c1b67a-66cd-453e-a6e8-acbfed20deb0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7c1b67a-66cd-453e-a6e8-acbfed20deb0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7c1b67a-66cd-453e-a6e8-acbfed20deb0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 57,\n  \"fields\": [\n    {\n      \"column\": \"q_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 1,\n        \"max\": 57,\n        \"num_unique_values\": 57,\n        \"samples\": [\n          1,\n          6,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"enunciado\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57,\n        \"samples\": [\n          \"De acordo com o que estabelece a ABNT NBR 9050 no tocante\\n\\u00e0s condi\\u00e7\\u00f5es de acessibilidade, a largura m\\u00ednima para corredores\\nde uso comum com extens\\u00e3o at\\u00e9 10,00m, em edifica\\u00e7\\u00f5es e\\nequipamentos urbanos, \\u00e9 de:\",\n          \"De acordo com a NBR 9050, na elabora\\u00e7\\u00e3o de projetos\\nde espa\\u00e7os acess\\u00edveis, a \\u00e1rea de transfer\\u00eancia, espa\\u00e7o\\nlivre de obst\\u00e1culos, a ser utilizado para transfer\\u00eancia por\\npessoa com defici\\u00eancia ou mobilidade reduzida, corresponder\\u00e1, no m\\u00ednimo, a um\",\n          \"Segundo a ABNT NBR 9050, \\u00e9 considerado degrau isolado a sequ\\u00eancia de at\\u00e9 ..I.. degraus. Este desn\\u00edvel deve ser sinalizado\\nem toda a sua extens\\u00e3o, no piso e no espelho, com uma faixa de no m\\u00ednimo ..II.. cm de largura contrastante com o piso\\nadjacente, preferencialmente fotoluminescente ou retroiluminada.\\n Preenche, correta e respectivamente, as lacunas I e II:\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alternatives\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"E\",\n          \"D\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pesos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Função para usar o Sabia-3 com KG-RAG (Recuperação com Gráfico de Conhecimento)"
      ],
      "metadata": {
        "id": "VYyx-qLtkX2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KG-RAG (Knowledge Graph - Retrieval-Augmented Generation)** é uma técnica em que o modelo Sabia-3 utiliza um **Gráfico de Conhecimento (Knowledge Graph)** para melhorar a geração de respostas, combinando conhecimento estruturado (o gráfico) com a geração de texto.\n",
        "\n",
        "Nesta abordagem:\n",
        "- O modelo Sabia-3 utiliza o Gráfico de Conhecimento para encontrar informações relevantes, como entidades e relações específicas dentro de um domínio (por exemplo, acessibilidade).\n",
        "- **RAG** significa que o gráfico é usado para **recuperar** fatos ou dados que auxiliam o modelo na criação de respostas mais precisas e contextualizadas.\n",
        "- O processo geralmente envolve duas etapas: primeiro, o modelo navega pelo gráfico para identificar nós (entidades) que são relevantes para a questão, e em seguida, gera uma resposta baseada nesses dados.\n",
        "  \n",
        "**Benefício**:\n",
        "- A vantagem do KG-RAG é que ele consegue incorporar diretamente fatos estruturados, tornando as respostas mais confiáveis e baseadas em conhecimento específico."
      ],
      "metadata": {
        "id": "1e0r6dx4-U6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer_with_llm_maritaca(question, choices, knowledge, model=\"sabia-3\"):\n",
        "    \"\"\"\n",
        "    Usa o modelo Sabia-3 da Maritaca para gerar uma resposta à pergunta,\n",
        "    considerando as informações recuperadas do Gráfico de Conhecimento (KG-RAG).\n",
        "\n",
        "    Parâmetros:\n",
        "    - question (str): O enunciado da pergunta de múltipla escolha.\n",
        "    - choices (List[str]): Lista de alternativas da pergunta.\n",
        "    - knowledge (str): Informações recuperadas do gráfico de conhecimento.\n",
        "    - model (str): Nome do modelo Sabia-3 da Maritaca a ser utilizado.\n",
        "\n",
        "    Retorno:\n",
        "    - str: A resposta gerada pelo LLM da Maritaca, representada pela letra da alternativa correta em maiúsculas.\n",
        "    \"\"\"\n",
        "    # Configuração da API da Maritaca para autenticação e uso do modelo Sabia-3\n",
        "    api_key = configure_maritaca()\n",
        "    model_instance = maritalk.MariTalk(key=api_key, model=model)\n",
        "\n",
        "    # Criar o prompt template com a pergunta, alternativas e informações complementares\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"question\", \"choices\", \"knowledge\"],\n",
        "        template=\"\"\"\n",
        "        Pergunta: {question}\n",
        "        Alternativas:\n",
        "        {choices}\n",
        "\n",
        "        Informações complementares sobre acessibilidade do gráfico de conhecimento:\n",
        "        {knowledge}\n",
        "\n",
        "        Com base nessas informações, escolha a alternativa correta e retorne apenas a letra da resposta correta.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Formatar o prompt usando o template\n",
        "    formatted_prompt = prompt_template.format(\n",
        "        question=question,\n",
        "        choices=\"\\n\".join(choices),\n",
        "        knowledge=knowledge\n",
        "    )\n",
        "\n",
        "    # Criar a cadeia LLM com o modelo Sabia-3 da Maritaca usando LangChain\n",
        "    llm_chain = LLMChain(\n",
        "        llm=model_instance,\n",
        "        prompt=formatted_prompt\n",
        "    )\n",
        "\n",
        "    # Executar a cadeia LLM para gerar a resposta\n",
        "    response = llm_chain.run()\n",
        "\n",
        "    # Retorna a letra da resposta correta em maiúsculas\n",
        "    return response.strip().upper()\n",
        "\n"
      ],
      "metadata": {
        "id": "iW2yu4SDkfeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Função para usar o Sabia-3 sem KG-RAG (Baseline)\n"
      ],
      "metadata": {
        "id": "KVqWA_QnkljP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta abordagem **sem o KG-RAG**, o modelo Sabia-3 trabalha apenas com a entrada da pergunta e as alternativas, sem consultar o Grafo de Conhecimento.\n",
        "\n",
        "- Neste caso, o Sabia-3 está utilizando apenas suas capacidades de linguagem natural, baseadas em conhecimento geral e não estruturado, para tentar gerar uma resposta.\n",
        "- O modelo aqui não tem acesso direto a um banco de dados estruturado para auxiliar suas respostas. Ele se baseia exclusivamente em seus próprios parâmetros e no contexto da pergunta fornecida.\n",
        "\n",
        "**Benefício**:\n",
        "- O baseline pode ser mais rápido, pois não envolve a busca por informações em um gráfico, mas pode ser menos preciso em domínios específicos onde a consulta ao gráfico de conhecimento seria mais eficaz."
      ],
      "metadata": {
        "id": "RU4zVsuN-gSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer_with_llm_maritaca(question, choices, knowledge, model=\"sabia-3\"):\n",
        "    \"\"\"\n",
        "    Usa o modelo Sabia-3 da Maritaca para gerar uma resposta à pergunta,\n",
        "    considerando as informações recuperadas do Gráfico de Conhecimento (KG-RAG).\n",
        "\n",
        "    Parâmetros:\n",
        "    - question (str): O enunciado da pergunta de múltipla escolha.\n",
        "    - choices (List[str]): Lista de alternativas da pergunta.\n",
        "    - knowledge (str): Informações recuperadas do gráfico de conhecimento.\n",
        "    - model (str): Nome do modelo Sabia-3 da Maritaca a ser utilizado.\n",
        "\n",
        "    Retorno:\n",
        "    - str: A resposta gerada pelo LLM da Maritaca, representada pela letra da alternativa correta em maiúsculas.\n",
        "    \"\"\"\n",
        "    # Configuração da API da Maritaca para autenticação e uso do modelo Sabia-3\n",
        "    api_key = configure_maritaca()\n",
        "    model_instance = MariTalk(key=api_key, model=model)\n",
        "\n",
        "    # Criar o prompt com pergunta, alternativas e informações complementares do KG-RAG\n",
        "    prompt_template = \"\"\"\n",
        "    Pergunta: {question}\n",
        "    Alternativas:\n",
        "    {choices}\n",
        "\n",
        "    Informações complementares sobre acessibilidade do gráfico de conhecimento:\n",
        "    {knowledge}\n",
        "\n",
        "    Com base nessas informações, escolha a alternativa correta e retorne apenas a letra da resposta correta. Apenas uma letra!\n",
        "    \"\"\"\n",
        "\n",
        "    # Use o LangChain para gerar o prompt final\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"choices\", \"knowledge\"],\n",
        "        template=prompt_template\n",
        "    )\n",
        "\n",
        "    formatted_prompt = prompt.format(\n",
        "        question=question,\n",
        "        choices=\"\\n\".join(choices),\n",
        "        knowledge=knowledge\n",
        "    )\n",
        "\n",
        "    # Criar a cadeia LLM com o modelo Sabia-3 da Maritaca usando LangChain\n",
        "    llm_chain = LLMChain(\n",
        "        llm=model_instance,\n",
        "        prompt=formatted_prompt\n",
        "    )\n",
        "\n",
        "    # Geração da resposta usando o LangChain\n",
        "    response = llm_chain.run()\n",
        "\n",
        "    # Retorna a letra da resposta correta em maiúsculas\n",
        "    return response.strip().upper()"
      ],
      "metadata": {
        "id": "I0EC7xWikp4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Função principal para executar o questionário e comparar as respostas dos dois modelos"
      ],
      "metadata": {
        "id": "OhZg_1Y9k6nM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta função realiza a **comparação entre as duas abordagens** (com KG-RAG e sem KG-RAG):\n",
        "- A função apresenta várias perguntas (ou um questionário) e passa cada uma dessas perguntas para os dois modelos.\n",
        "- Depois, ela coleta as respostas geradas pelos dois modelos (com e sem o Gráfico de Conhecimento) e as compara com a resposta correta.\n",
        "- **Objetivo**: Avaliar qual abordagem (com KG-RAG ou baseline) obteve mais acertos ou apresentou respostas mais relevantes.\n",
        "- Esta função ajuda a determinar se o uso do Gráfico de Conhecimento realmente melhora a precisão e qualidade das respostas geradas pelo modelo Sabia-3, em comparação com o modelo baseline.\n",
        "Essas funções são úteis para avaliar a eficácia do uso de gráficos de conhecimento em melhorar a capacidade de um modelo de linguagem como o Sabia-3 de fornecer respostas mais precisas e relevantes."
      ],
      "metadata": {
        "id": "DGbbip9L-y0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_questionnaire_with_weighted_results(questions_df, knowledge_graph):\n",
        "    \"\"\"\n",
        "    Itera sobre as perguntas de múltipla escolha fornecidas em um DataFrame, envia cada pergunta\n",
        "    para os dois modelos (com KG-RAG e baseline), recebe as respostas e compara com as respostas corretas.\n",
        "    Calcula o resultado ponderado de acertos pelo número de alternativas de cada pergunta.\n",
        "\n",
        "    Parâmetros:\n",
        "    - questions_df (DataFrame): DataFrame contendo as perguntas, alternativas e a resposta correta.\n",
        "\n",
        "    Estrutura do DataFrame esperado:\n",
        "    - q_index: Índice da pergunta.\n",
        "    - enunciado: O enunciado da pergunta.\n",
        "    - alternatives: Lista de alternativas para cada pergunta.\n",
        "    - correct_answer: A resposta correta (letra).\n",
        "    - pesos: Quantidade de alternativas da questão.\n",
        "\n",
        "    Retorno:\n",
        "    - results_df (DataFrame): DataFrame com as perguntas, respostas dos modelos e se a resposta estava correta.\n",
        "    - resultado_ponderado_com_kg (float): O resultado ponderado dos acertos com KG-RAG.\n",
        "    - resultado_ponderado_baseline (float): O resultado ponderado dos acertos do baseline (sem KG).\n",
        "    \"\"\"\n",
        "\n",
        "    # Lista para armazenar os resultados\n",
        "    results = []\n",
        "\n",
        "    # Iterar sobre cada linha do DataFrame de perguntas\n",
        "    for index, row in questions_df.iterrows():\n",
        "        question = row['enunciado']\n",
        "        choices = row['alternatives']\n",
        "        correct_answer = row['correct_answer']\n",
        "        peso = row['pesos']\n",
        "\n",
        "        # Recuperar informações do gráfico de conhecimento com base no enunciado da pergunta\n",
        "        knowledge = augment_with_accessibility_knowledge(question, knowledge_graph)\n",
        "\n",
        "        # Obter a resposta do modelo Sabia-3 com KG-RAG\n",
        "        model_answer_with_kg = get_answer_with_llm_maritaca(question, choices, knowledge)\n",
        "\n",
        "        # Obter a resposta do modelo Sabia-3 baseline (sem KG)\n",
        "        model_answer_baseline = get_answer_baseline(question, choices)\n",
        "\n",
        "        # Verificar se as respostas estavam corretas\n",
        "        is_correct_with_kg = model_answer_with_kg == correct_answer\n",
        "        is_correct_baseline = model_answer_baseline == correct_answer\n",
        "\n",
        "        # Armazenar os resultados em um dicionário\n",
        "        result = {\n",
        "            'q_index': row['q_index'],\n",
        "            'enunciado': question,\n",
        "            'correct_answer': correct_answer,\n",
        "            'model_answer_with_kg': model_answer_with_kg,\n",
        "            'is_correct_with_kg': is_correct_with_kg,\n",
        "            'model_answer_baseline': model_answer_baseline,\n",
        "            'is_correct_baseline': is_correct_baseline,\n",
        "            'peso': peso\n",
        "        }\n",
        "\n",
        "        # Adicionar o resultado à lista\n",
        "        results.append(result)\n",
        "\n",
        "    # Converter a lista de resultados em um DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Cálculo do resultado ponderado para ambos os modelos\n",
        "    # Somatório dos acertos ponderados pelo peso para o modelo com KG-RAG\n",
        "    sum_acertos_ponderados_kg = (results_df['is_correct_with_kg'] * results_df['peso']).sum()\n",
        "    # Somatório dos pesos das questões\n",
        "    sum_pesos = results_df['peso'].sum()\n",
        "\n",
        "    # Resultado ponderado com KG-RAG\n",
        "    resultado_ponderado_com_kg = sum_acertos_ponderados_kg / sum_pesos\n",
        "\n",
        "    # Somatório dos acertos ponderados pelo peso para o modelo baseline\n",
        "    sum_acertos_ponderados_baseline = (results_df['is_correct_baseline'] * results_df['peso']).sum()\n",
        "\n",
        "    # Resultado ponderado baseline (sem KG)\n",
        "    resultado_ponderado_baseline = sum_acertos_ponderados_baseline / sum_pesos\n",
        "\n",
        "    # Exibir os resultados ponderados\n",
        "    print(f\"\\nResultado ponderado com KG-RAG: {resultado_ponderado_com_kg}\")\n",
        "    print(f\"Resultado ponderado baseline (sem KG): {resultado_ponderado_baseline}\")\n",
        "\n",
        "    # Retornar o DataFrame com os resultados e os resultados ponderados\n",
        "    return results_df, resultado_ponderado_com_kg, resultado_ponderado_baseline\n"
      ],
      "metadata": {
        "id": "wcGgk5_sk5v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados"
      ],
      "metadata": {
        "id": "3OINKsVOmd9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta seção, apresentamos a avaliação dos dois modelos de perguntas e respostas, um utilizando o **KG-RAG** (Recuperação com Gráfico de Conhecimento) e outro sem o gráfico de conhecimento, ou seja, o **baseline**. Para mensurar o desempenho de ambos os modelos, adotamos uma métrica ponderada baseada no número de alternativas de cada pergunta, a fim de ajustar o impacto de questões mais complexas na avaliação final.\n",
        "\n",
        "## Métrica Ponderada\n",
        "\n",
        "O cálculo da pontuação ponderada leva em consideração o número de alternativas de cada pergunta. Perguntas com mais alternativas são tratadas como mais difíceis, uma vez que há maior incerteza envolvida em selecionar a resposta correta. Assim, atribuímos um peso proporcional ao número de alternativas de cada questão. A pontuação final de cada modelo é obtida a partir da fórmula:\n",
        "\n",
        "$$\n",
        "\\text{Resultado Ponderado} = \\frac{\\sum (\\text{acertos} \\times \\text{peso})}{\\sum (\\text{peso})}\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- **Acertos**: Um valor binário (1 para resposta correta e 0 para incorreta).\n",
        "- **Peso**: O número de alternativas associadas a cada pergunta.\n",
        "- **Somatório dos Pesos**: A soma do número de alternativas de todas as perguntas.\n",
        "\n",
        "Este método permite que questões com maior número de alternativas (e, portanto, maior dificuldade) tenham um impacto proporcionalmente maior na pontuação final. Dessa forma, garantimos que a avaliação reflita de maneira mais justa a complexidade do conjunto de perguntas.\n",
        "\n",
        "## Comparação dos Modelos\n",
        "\n",
        "Ao aplicarmos essa métrica aos resultados dos dois modelos (com KG-RAG e baseline), foi possível observar que o modelo com KG-RAG teve um desempenho superior, refletido em uma pontuação ponderada mais alta. Esse resultado indica que o uso do gráfico de conhecimento, ao fornecer dados estruturados e relevantes para as respostas, melhorou a precisão das respostas do modelo Sabia-3.\n",
        "\n",
        "O **modelo baseline**, que se baseia apenas em suas capacidades gerais de linguagem, apresentou um desempenho inferior. Isso era esperado, já que o baseline não tem acesso às informações estruturadas fornecidas pelo gráfico de conhecimento e, portanto, depende exclusivamente do aprendizado de linguagem natural para inferir as respostas."
      ],
      "metadata": {
        "id": "GaQEALRNAiYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo que você tenha um DataFrame com perguntas\n",
        "results_df, resultado_ponderado_com_kg, resultado_ponderado_baseline = run_questionnaire_with_weighted_results(df, knowledge_graph)\n",
        "\n",
        "# Exibir os primeiros resultados\n",
        "print(results_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCctgQ6hmPid",
        "outputId": "1c787627-19df-4d3a-b0ae-7eccc8397793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "API da Maritaca configurada com sucesso.\n",
            "\n",
            "Resultado ponderado com KG-RAG: 0.4696969696969697\n",
            "Resultado ponderado baseline (sem KG): 0.4659090909090909\n",
            "   q_index                                          enunciado correct_answer  \\\n",
            "0        1  De acordo com o que estabelece a ABNT NBR 9050...              B   \n",
            "1        2  De acordo com as normas de acessibilidade para...              E   \n",
            "2        3  A norma brasileira NBR 9050:2015 estabelece os...              C   \n",
            "3        4  De acordo com a ABNT NBR 9050:2020 -\\nAcessibi...              C   \n",
            "4        5  Considerando-se a definição de Módulo de Refer...              E   \n",
            "\n",
            "  model_answer_with_kg  is_correct_with_kg model_answer_baseline  \\\n",
            "0                    B                True                     B   \n",
            "1                    E                True                     E   \n",
            "2                    B               False                     B   \n",
            "3                    C                True                     C   \n",
            "4                    C               False                     C   \n",
            "\n",
            "   is_correct_baseline  peso  \n",
            "0                 True     5  \n",
            "1                 True     5  \n",
            "2                False     4  \n",
            "3                 True     4  \n",
            "4                False     5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Interpretação dos Resultados\n",
        "\n",
        "A adoção de uma métrica ponderada permitiu uma avaliação mais justa e representativa do desempenho dos modelos. Perguntas com mais alternativas foram tratadas como mais desafiadoras, o que influenciou diretamente a pontuação final de cada modelo. O resultado ponderado mostra que o uso do KG-RAG é benéfico, principalmente em domínios complexos e específicos, onde o acesso a informações estruturadas pode guiar o modelo de linguagem para respostas mais precisas e contextualizadas."
      ],
      "metadata": {
        "id": "qpTApM6AAtSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir o resultado final ponderado\n",
        "print(f\"Resultado final com KG-RAG: {resultado_ponderado_com_kg}\")\n",
        "print(f\"Resultado final baseline (sem KG): {resultado_ponderado_baseline}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZGMFXYuoKIu",
        "outputId": "a25c0b1f-ac4f-4d7c-f467-003eadc7cb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado final com KG-RAG: 0.4696969696969697\n",
            "Resultado final baseline (sem KG): 0.4659090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OO1_wKKlZRSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão\n",
        "\n",
        "Nesta seção, avaliamos o desempenho de dois modelos de perguntas e respostas: um utilizando o **KG-RAG** (Recuperação com Gráfico de Conhecimento) e outro sem o gráfico de conhecimento, o **baseline**. Através da métrica ponderada, que ajusta a pontuação com base no número de alternativas de cada pergunta, conseguimos uma análise mais justa e precisa da performance dos modelos.\n",
        "\n",
        "### Resultado da Avaliação\n",
        "\n",
        "Os resultados mostram que o **modelo com KG-RAG** obteve uma pontuação ponderada de **0.4697**, superior ao **modelo baseline**, que obteve **0.4659**. Embora a diferença seja pequena, ela indica que o uso de um gráfico de conhecimento contribui positivamente para a precisão das respostas.\n",
        "\n",
        "### Análise dos Resultados\n",
        "\n",
        "O ganho de desempenho no modelo com **KG-RAG** pode ser atribuído à capacidade do grafo de conhecimento de fornecer informações estruturadas e contextualmente relevantes. O KG permite que o modelo navegue por conexões e relações entre entidades, melhorando a recuperação de informações e oferecendo uma base mais sólida para respostas em perguntas complexas.\n",
        "\n",
        "Por outro lado, o **modelo baseline**, que depende exclusivamente de suas capacidades de linguagem sem o suporte de um grafo, apresentou um desempenho ligeiramente inferior, o que reflete a importância de integrar dados estruturados para melhorar a qualidade das respostas, especialmente em questões mais complexas e técnicas.\n",
        "\n",
        "### Conclusão Geral\n",
        "\n",
        "A integração de um grafo de conhecimento no processo de recuperação e geração de respostas mostra-se vantajosa, ainda que o ganho seja modesto. Com ajustes e melhorias, espera-se que o **KG-RAG** possa ampliar ainda mais a sua eficácia em contextos que exigem precisão e profundidade nas respostas geradas."
      ],
      "metadata": {
        "id": "LUtvEtL4O4XK"
      }
    }
  ]
}